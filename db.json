{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/random/source/favicon.ico","path":"favicon.ico","modified":1,"renderable":1},{"_id":"themes/random/source/css/blank.gif","path":"css/blank.gif","modified":1,"renderable":1},{"_id":"themes/random/source/css/fancybox_loading@2x.gif","path":"css/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/random/source/css/fancybox_overlay.png","path":"css/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/random/source/css/fancybox_loading.gif","path":"css/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/random/source/css/fancybox_sprite.png","path":"css/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/random/source/css/fancybox_sprite@2x.png","path":"css/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/random/source/css/highlight-railscasts.css","path":"css/highlight-railscasts.css","modified":1,"renderable":1},{"_id":"themes/random/source/css/jquery.fancybox-thumbs.css","path":"css/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/random/source/css/jquery.fancybox.css","path":"css/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/random/source/css/plyr.css","path":"css/plyr.css","modified":1,"renderable":1},{"_id":"themes/random/source/css/next.png","path":"css/next.png","modified":1,"renderable":1},{"_id":"themes/random/source/css/prev.png","path":"css/prev.png","modified":1,"renderable":1},{"_id":"themes/random/source/css/random.styl","path":"css/random.styl","modified":1,"renderable":1},{"_id":"themes/random/source/css/vegas.min.css","path":"css/vegas.min.css","modified":1,"renderable":1},{"_id":"themes/random/source/css/sprite.svg","path":"css/sprite.svg","modified":1,"renderable":1},{"_id":"themes/random/source/js/highlight.pack.js","path":"js/highlight.pack.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/jquery.fancybox-thumbs.js","path":"js/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/jquery.fancybox.pack.js","path":"js/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/jquery.mousewheel.pack.js","path":"js/jquery.mousewheel.pack.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/plyr.js","path":"js/plyr.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/random.js","path":"js/random.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/vegas.min.js","path":"js/vegas.min.js","modified":1,"renderable":1},{"_id":"themes/random/source/js/jquery-2.2.3.min.js","path":"js/jquery-2.2.3.min.js","modified":1,"renderable":1},{"_id":"themes/random/source/css/iconfont/iconfont.css","path":"css/iconfont/iconfont.css","modified":1,"renderable":1},{"_id":"themes/random/source/css/iconfont/iconfont.eot","path":"css/iconfont/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/random/source/css/iconfont/iconfont.svg","path":"css/iconfont/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/random/source/css/iconfont/iconfont.ttf","path":"css/iconfont/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/random/source/css/iconfont/iconfont.woff","path":"css/iconfont/iconfont.woff","modified":1,"renderable":1}],"Cache":[{"_id":"themes/random/LICENSE","hash":"03bec2e3a3b7bad96e2688d57197c99b494dcdb5","modified":1466575630717},{"_id":"themes/random/README.CN.md","hash":"197e736dc03c31a666b54b2c26f56c7e9c8169c6","modified":1466575630718},{"_id":"themes/random/.gitignore","hash":"6993cdad70ce92d2734ccd7a0a944e539a79e738","modified":1466575630716},{"_id":"themes/random/README.md","hash":"26bc4bf3b66583fb8a9d400722de223b346d4586","modified":1466575630718},{"_id":"themes/random/_config.yml","hash":"e33e6e9d4d0a26390118a5095139bafb4a5fa023","modified":1466581960559},{"_id":"source/_posts/centos-scrapy-ghost.py.md","hash":"4f720fdbe944159e5e3beba5a4048fca0ea8d6d5","modified":1468411374373},{"_id":"source/_posts/hello-world.md","hash":"153e516fc3e55ecc19c34344a4a19a8396a6d891","modified":1468565798880},{"_id":"source/_posts/hmm-memm-crf.md","hash":"2f3c81c91d08c31b14af67a9ab667ac69029ff48","modified":1468669783107},{"_id":"source/_posts/img2txt.md","hash":"abf4584c83a48e960f0d2855934be244c77dc76a","modified":1469024016866},{"_id":"source/_posts/zhihu-link.md","hash":"5407fa07f57a425c7c414dc3bccff8fe60e45ceb","modified":1469022587806},{"_id":"source/about/index.md","hash":"449909708312f92ce5159f61c0815d08df6dcbbc","modified":1466125557734},{"_id":"source/categories/index.md","hash":"174e63bdf5768ee16d002dad34de812b200f4ae2","modified":1466125557734},{"_id":"source/tags/index.md","hash":"63773e15ffc42a9c4488f47fbdaf1a5f978a5c79","modified":1466125557735},{"_id":"themes/random/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1466575630522},{"_id":"themes/random/.git/config","hash":"217783bf289ea80627d1f9b35858881f03efb06e","modified":1466575630525},{"_id":"themes/random/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1466575625530},{"_id":"themes/random/.git/index","hash":"f68802f2b1911c3dd32549ce9196dc35efba9e0a","modified":1466585131672},{"_id":"themes/random/.git/packed-refs","hash":"fa836080405cb6079c1c640bd65cae6be761a7c7","modified":1466575630519},{"_id":"themes/random/languages/en.yml","hash":"1435cf69d9607a7912f647d861ec4a30a8c08dba","modified":1466575630720},{"_id":"themes/random/languages/zh-CN.yml","hash":"1f18252ba42703ccdecd9ce01ac57a829b99d9fe","modified":1466575630720},{"_id":"themes/random/layout/archive.swig","hash":"23f96a38b04d116aedbed0820d0eb0c9a4b8622c","modified":1466575630722},{"_id":"themes/random/layout/category.swig","hash":"58492ccd8a863b06742f89dcac97782dfd86e43a","modified":1466575630722},{"_id":"themes/random/layout/index.swig","hash":"411520dcdcf83f16e19cbf039f6aa544a6c332d3","modified":1466575630730},{"_id":"themes/random/layout/page.swig","hash":"146e6587c08e6bea08eec98b45b8e0438793cfd5","modified":1466575630730},{"_id":"themes/random/layout/post.swig","hash":"10570f6c48f4accf65cff253639b03ee5cd2e993","modified":1466575630731},{"_id":"themes/random/layout/tag.swig","hash":"340ca3d9dceff6827865ffceabbfbd6eb75a927f","modified":1466575630731},{"_id":"themes/random/source/favicon.ico","hash":"96b9a549337c2bec483c2879eeafa4d1f8748fed","modified":1466575630767},{"_id":"themes/random/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1466575625555},{"_id":"themes/random/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1466575625588},{"_id":"themes/random/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1466575625603},{"_id":"themes/random/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1466575625603},{"_id":"themes/random/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1466575625613},{"_id":"themes/random/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1466575625614},{"_id":"themes/random/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1466575625626},{"_id":"themes/random/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1466575625627},{"_id":"themes/random/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1466575625628},{"_id":"themes/random/.git/logs/HEAD","hash":"f10f4700b496f0c2825b977927dee73df01dc7f1","modified":1466575630524},{"_id":"themes/random/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1466575625629},{"_id":"themes/random/layout/includes/baidu-tongji.swig","hash":"3b88cbae8980212859e898d7b3c16e839f99cd80","modified":1466575630722},{"_id":"themes/random/layout/includes/duoshuo.swig","hash":"3e97d0c6b0243bb16e3d76ba3f481338486322c9","modified":1466575630723},{"_id":"themes/random/layout/includes/disqus.swig","hash":"d81bc248e3926019e21deaac52123678ae6af55b","modified":1466575630723},{"_id":"themes/random/layout/includes/footer.swig","hash":"1512b1b974bc7bd0cf7a04234c9ccf32500ed2c3","modified":1466575630724},{"_id":"themes/random/layout/includes/gallery.swig","hash":"7d749acb90d424f2d04587fca396e578bf1fabb5","modified":1466575630724},{"_id":"themes/random/layout/includes/google-analytics.swig","hash":"3e4cad2175c599edd6f3e66f0a738a57e6eeffd7","modified":1466575630725},{"_id":"themes/random/layout/includes/head.swig","hash":"6dfd7afb26d79729a90bf2dd3c453d43e751d58b","modified":1466575630725},{"_id":"themes/random/layout/includes/jiathis.swig","hash":"53fb1038a56b2428c6ff3ffae01203dddc112f6a","modified":1466575630726},{"_id":"themes/random/layout/includes/layout.swig","hash":"d0a884710325964ad236c8dde66be96d34c14dda","modified":1466575630726},{"_id":"themes/random/layout/includes/pagination.swig","hash":"1c4c841816c7fbfd4d34c32f05797264942d6a22","modified":1466575630727},{"_id":"themes/random/layout/includes/post-title-item.swig","hash":"10238491556e3104b5ee5ca52df3eb50029cc47d","modified":1466575630727},{"_id":"themes/random/layout/includes/recent-posts.swig","hash":"281446641c5d33762bd00d4fa28447aeb2fa5d18","modified":1466575630727},{"_id":"themes/random/layout/includes/side-pagination.swig","hash":"f3d4b832aece4a22eb9a5503063ccd384dc4538d","modified":1466575630728},{"_id":"themes/random/layout/includes/social-icon.swig","hash":"665510baf91266f9693cbcb7b4b47b6f6e6a4947","modified":1466575630728},{"_id":"themes/random/layout/includes/toc.swig","hash":"704b68b52663734e00e2bd4e21c51fab92868e12","modified":1466575630729},{"_id":"themes/random/layout/includes/user-card.swig","hash":"7c17b70595754638043b3eddee626420c27dffd7","modified":1466575630729},{"_id":"themes/random/layout/includes/uyan.swig","hash":"3803b211124a7967aebf5fb96870b0f8b4be3e6f","modified":1466575630729},{"_id":"themes/random/source/css/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1466575630732},{"_id":"themes/random/source/css/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1466575630733},{"_id":"themes/random/source/css/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1466575630734},{"_id":"themes/random/source/css/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1466575630733},{"_id":"themes/random/source/css/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1466575630734},{"_id":"themes/random/source/css/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1466575630735},{"_id":"themes/random/source/css/highlight-railscasts.css","hash":"1bb2dd8ccba3e33aa3fd419bad757b0710ca7bf3","modified":1466575630735},{"_id":"themes/random/source/css/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1466575630762},{"_id":"themes/random/source/css/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1466575630763},{"_id":"themes/random/source/css/plyr.css","hash":"29202451dd2547739b2b763952ff58c8a4d11df9","modified":1466575630764},{"_id":"themes/random/source/css/next.png","hash":"1bf3e61fbe6858bd9d154e23a477a06307f80436","modified":1466575630763},{"_id":"themes/random/source/css/prev.png","hash":"c35bf41b4597a371e80ffdaf338b5693a082a5f4","modified":1466575630764},{"_id":"themes/random/source/css/random.styl","hash":"9a72972f08947b9e4fde8f4d085a10bca97e53e7","modified":1466582214977},{"_id":"themes/random/source/css/vegas.min.css","hash":"5810e20875386f98565b69de5ca8ee1d0a6d1feb","modified":1466575630766},{"_id":"themes/random/source/css/sprite.svg","hash":"4ed6a0d335ce214ec00fc9e56867687798a53ee3","modified":1466575630765},{"_id":"themes/random/source/js/highlight.pack.js","hash":"8407be86478389b07f54296e976a1d6f0a6cf69a","modified":1466575630786},{"_id":"themes/random/source/js/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1466575630788},{"_id":"themes/random/source/js/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1466575630795},{"_id":"themes/random/source/js/jquery.mousewheel.pack.js","hash":"5d6f224e3080fd4066f8ef5c63d3f467e9d29e66","modified":1466575630796},{"_id":"themes/random/source/js/plyr.js","hash":"58ddde47173120b23f752872a535d7b3c9166ae8","modified":1466575630797},{"_id":"themes/random/source/js/random.js","hash":"2ff5837668e5a8fe5f53dcfe9d0b8c005e58ced3","modified":1466575630798},{"_id":"themes/random/source/js/vegas.min.js","hash":"49a911f3434d0d5a7d0372129e4a80b4b4bb3923","modified":1466575630798},{"_id":"themes/random/source/js/jquery-2.2.3.min.js","hash":"223a49c329f0f0a651d142be9dadc95008678d26","modified":1466575630788},{"_id":"themes/random/.git/objects/pack/pack-7f0245a058983d2de7f7843f803886e99be35bae.idx","hash":"b72944ea7a99711417311977337f808833882506","modified":1466575630190},{"_id":"themes/random/.git/refs/heads/master","hash":"24ea10a0bcde23d65d704386d054ddaa0a1edbf6","modified":1466575630523},{"_id":"themes/random/source/css/iconfont/iconfont.css","hash":"1955cec6e833e3b782bb6b150682ecbb3b0d9c1f","modified":1466575630736},{"_id":"themes/random/source/css/iconfont/iconfont.eot","hash":"b4d3e20bd54983f7d9f95e789e9e28d056592f11","modified":1466575630737},{"_id":"themes/random/source/css/iconfont/iconfont.svg","hash":"ed867bba0ead29c55997b7b9568ee5c0499a4379","modified":1466575630737},{"_id":"themes/random/source/css/iconfont/iconfont.ttf","hash":"3a02ec5b0453b13944311361e95081f1c3085f6d","modified":1466575630738},{"_id":"themes/random/source/css/iconfont/iconfont.woff","hash":"5c122ce49b9fc0c05c0e0f88da009469e5286a55","modified":1466575630738},{"_id":"themes/random/.git/logs/refs/heads/master","hash":"f10f4700b496f0c2825b977927dee73df01dc7f1","modified":1466575630523},{"_id":"themes/random/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1466575630522},{"_id":"themes/random/.git/logs/refs/remotes/origin/HEAD","hash":"f10f4700b496f0c2825b977927dee73df01dc7f1","modified":1466575630522},{"_id":"themes/random/.git/objects/pack/pack-7f0245a058983d2de7f7843f803886e99be35bae.pack","hash":"11b9bb61b2bb694d8533c34bd174ad23e01158b8","modified":1466575630239},{"_id":"public/search.xml","hash":"fe7b067a3672bec56c3c1e04655cbae5a6b3c814","modified":1469024038380},{"_id":"public/favicon.ico","hash":"96b9a549337c2bec483c2879eeafa4d1f8748fed","modified":1469024038466},{"_id":"public/css/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1469024038467},{"_id":"public/css/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1469024038467},{"_id":"public/css/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1469024038467},{"_id":"public/css/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1469024038467},{"_id":"public/css/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1469024038467},{"_id":"public/css/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1469024038467},{"_id":"public/css/next.png","hash":"1bf3e61fbe6858bd9d154e23a477a06307f80436","modified":1469024038468},{"_id":"public/css/prev.png","hash":"c35bf41b4597a371e80ffdaf338b5693a082a5f4","modified":1469024038468},{"_id":"public/css/sprite.svg","hash":"4ed6a0d335ce214ec00fc9e56867687798a53ee3","modified":1469024038468},{"_id":"public/css/iconfont/iconfont.eot","hash":"b4d3e20bd54983f7d9f95e789e9e28d056592f11","modified":1469024038468},{"_id":"public/css/iconfont/iconfont.svg","hash":"ed867bba0ead29c55997b7b9568ee5c0499a4379","modified":1469024038468},{"_id":"public/css/iconfont/iconfont.ttf","hash":"3a02ec5b0453b13944311361e95081f1c3085f6d","modified":1469024038468},{"_id":"public/css/iconfont/iconfont.woff","hash":"5c122ce49b9fc0c05c0e0f88da009469e5286a55","modified":1469024038468},{"_id":"public/index.html","hash":"61275ca883d5ca9669b8a996778b00ab6e8ae5ea","modified":1469024038848},{"_id":"public/about/index.html","hash":"1c036648325f6c66af930475f9e49a9f20bec2e1","modified":1469024038862},{"_id":"public/tags/index.html","hash":"919f35869888a175b2349902aca43e7700b6e4b7","modified":1469024038863},{"_id":"public/categories/index.html","hash":"ce0aef9dbad862623dacef6fdf26ac8411dc637a","modified":1469024038863},{"_id":"public/2016/07/20/img2txt/index.html","hash":"59213dcc16c423b51527731a9328d92f0a199bfe","modified":1469024038863},{"_id":"public/2016/06/16/centos-scrapy-ghost.py/index.html","hash":"4ffa59fe4e97d61743581908e3776bc93e11979e","modified":1469024038863},{"_id":"public/2016/06/12/hello-world/index.html","hash":"b000f2dc976157e5a178e4b2def08aa564bfb76d","modified":1469024038863},{"_id":"public/categories/Reviews/index.html","hash":"f13255ee5fc5920a775694b253cb6aee8eb2c81a","modified":1469024038863},{"_id":"public/categories/Site-Est/index.html","hash":"7b6795715271cea8e87927ffac8c264e8be1987c","modified":1469024038863},{"_id":"public/categories/NLP/index.html","hash":"91e606137902ce806eec9c0f57cb35c9bb704e07","modified":1469024038863},{"_id":"public/categories/Crawler/index.html","hash":"31787a388db18bc14fec4b07e65f7860562f85c1","modified":1469024038863},{"_id":"public/categories/Fun/index.html","hash":"2eccd734c54efcfee66c9112694bf5203a486e17","modified":1469024038863},{"_id":"public/archives/index.html","hash":"22d206490bc0f6adebd84b03b1f5e24de000d899","modified":1469024038863},{"_id":"public/archives/2016/index.html","hash":"bc8e7cc7590c5caa71d7be0e8ca03351d9733c17","modified":1469024038863},{"_id":"public/archives/2016/06/index.html","hash":"1d41dbae173978b08ea4ba238bd20b9098ccf8f5","modified":1469024038863},{"_id":"public/archives/2016/07/index.html","hash":"3b2aa06e1a7dc738a09624825a5d94fc1b83f5a7","modified":1469024038863},{"_id":"public/tags/CentOS/index.html","hash":"b9e0622d1b8334ab276952d1619f8ba90efd836e","modified":1469024038864},{"_id":"public/tags/Scrapy/index.html","hash":"3d75744ba8c48df9b5d0b2daf817d20b7ef88b75","modified":1469024038864},{"_id":"public/tags/ghost-py/index.html","hash":"ce662227ec15fdb12b34738d73332400b5688533","modified":1469024038864},{"_id":"public/tags/python/index.html","hash":"f9e91a218d71d2aa012ee77a36b197b0ab79094f","modified":1469024038864},{"_id":"public/tags/English/index.html","hash":"02fd3736e4fd2090947b321a233ae1770fdf5465","modified":1469024038864},{"_id":"public/tags/Hexo/index.html","hash":"19a0bbbc60a9f77ace411c1bd7a1cfa6baa2b290","modified":1469024038864},{"_id":"public/tags/HMM/index.html","hash":"5bf92c704365656346fd0e2db5368bc87c4a3432","modified":1469024038864},{"_id":"public/tags/MEMM/index.html","hash":"81c63aacaac69775c4627ef365b659a870a6a58b","modified":1469024038864},{"_id":"public/tags/CRF/index.html","hash":"fb247e1e1a7951ca1c55169dc6586ecb69a01a5f","modified":1469024038864},{"_id":"public/tags/zhihu/index.html","hash":"7dc25bef1e321decc4f0dd5a12930662ddae1ee8","modified":1469024038864},{"_id":"public/tags/Neo4j/index.html","hash":"7d10fde7598513c6ceec43bdab1caca07ef96703","modified":1469024038864},{"_id":"public/tags/PIL/index.html","hash":"5d421065a947d08263d3a1d30eeafb2b9759e517","modified":1469024038864},{"_id":"public/css/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1469024038864},{"_id":"public/css/plyr.css","hash":"29202451dd2547739b2b763952ff58c8a4d11df9","modified":1469024038864},{"_id":"public/css/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1469024038865},{"_id":"public/css/highlight-railscasts.css","hash":"a6d2043478fae5915926914cbd96fe9b706d98a6","modified":1469024038865},{"_id":"public/css/random.css","hash":"264edb971f706a5717b3dc728df3654d74023f8f","modified":1469024038865},{"_id":"public/css/vegas.min.css","hash":"5810e20875386f98565b69de5ca8ee1d0a6d1feb","modified":1469024038865},{"_id":"public/js/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1469024038865},{"_id":"public/js/jquery.mousewheel.pack.js","hash":"1e1b44eb7cfade680c52d8748846425ecd809bfd","modified":1469024038865},{"_id":"public/js/random.js","hash":"e678af85471e86c3e25a7709496d517e50008d7a","modified":1469024038865},{"_id":"public/js/vegas.min.js","hash":"8d24ba5346a600c4b77ef39d68ee924ab48c8790","modified":1469024038865},{"_id":"public/css/iconfont/iconfont.css","hash":"4d5f8113307fbb6b99df0ee2ce5817af5137ec27","modified":1469024038865},{"_id":"public/2016/07/14/hmm-memm-crf/index.html","hash":"6a9bf1fcc0e9240b620a41108c42806e3f2e05ec","modified":1469024038865},{"_id":"public/2016/06/29/zhihu-link/index.html","hash":"f61d27ea59d32e25da5f6bcf13d6c06f79be398a","modified":1469024038865},{"_id":"public/js/highlight.pack.js","hash":"87868df3be2e575e47d6218ea08c0e5922808318","modified":1469024038865},{"_id":"public/js/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1469024038866},{"_id":"public/js/plyr.js","hash":"11e09c25a5821fc08880b8ab1f691ad58780bde3","modified":1469024038866},{"_id":"public/js/jquery-2.2.3.min.js","hash":"e3dbb65f2b541d842b50d37304b0102a2d5f2387","modified":1469024038866}],"Category":[{"name":"Reviews","_id":"ciquyzdgl0003ewc5muf5ldon"},{"name":"Site Est","_id":"ciquyzdgv0008ewc5m4f1u4ol"},{"name":"NLP","_id":"ciquyzdgy000bewc5rouwev2v"},{"name":"Crawler","_id":"ciquyzdh0000eewc53ago5nup"},{"name":"Fun","_id":"ciquyzdh3000hewc54ielb52p"}],"Data":[],"Page":[{"title":"About","date":"2016-06-12T11:19:01.000Z","type":"about","comments":0,"photos":["https://avatars3.githubusercontent.com/u/16516510?v=3&s=460"],"_content":"\n# About Me\nMy name is Haotian Wu(吴昊天). I'm a master student in [School of Computer Science & Engineering](http://cse.seu.edu.cn/en/index.html) at [Southeast University](http://www.seu.edu.cn/english/main.htm) and will graduate in Summer 2018.\n* Research Interests:\n  * Web Crawler\n  * Data Mining & Visualization\n  * Ad Hoc Networks\n* Sports: \n  * Badminton\n  * Swimming\n\n# Contact\nJust to avoid spams, here is the Base64 code of my e-mail address: \n`aGFvdGlhbnd1c2V1QGdtYWlsLmNvbQ==`","source":"about/index.md","raw":"---\ntitle: About\ndate: 2016-06-12 19:19:01\ntype: \"about\"\ncomments: false\nphotos:\n - https://avatars3.githubusercontent.com/u/16516510?v=3&s=460\n---\n\n# About Me\nMy name is Haotian Wu(吴昊天). I'm a master student in [School of Computer Science & Engineering](http://cse.seu.edu.cn/en/index.html) at [Southeast University](http://www.seu.edu.cn/english/main.htm) and will graduate in Summer 2018.\n* Research Interests:\n  * Web Crawler\n  * Data Mining & Visualization\n  * Ad Hoc Networks\n* Sports: \n  * Badminton\n  * Swimming\n\n# Contact\nJust to avoid spams, here is the Base64 code of my e-mail address: \n`aGFvdGlhbnd1c2V1QGdtYWlsLmNvbQ==`","updated":"2016-06-17T01:05:57.734Z","path":"about/index.html","layout":"page","_id":"ciquyzdja0017ewc531ho518v","content":"<h1 id=\"About-Me\"><a href=\"#About-Me\" class=\"headerlink\" title=\"About Me\"></a>About Me</h1><p>My name is Haotian Wu(吴昊天). I’m a master student in <a href=\"http://cse.seu.edu.cn/en/index.html\" target=\"_blank\" rel=\"external\">School of Computer Science &amp; Engineering</a> at <a href=\"http://www.seu.edu.cn/english/main.htm\" target=\"_blank\" rel=\"external\">Southeast University</a> and will graduate in Summer 2018.</p>\n<ul>\n<li>Research Interests:<ul>\n<li>Web Crawler</li>\n<li>Data Mining &amp; Visualization</li>\n<li>Ad Hoc Networks</li>\n</ul>\n</li>\n<li>Sports: <ul>\n<li>Badminton</li>\n<li>Swimming</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h1><p>Just to avoid spams, here is the Base64 code of my e-mail address:<br><code>aGFvdGlhbnd1c2V1QGdtYWlsLmNvbQ==</code></p>\n","excerpt":"","more":"<h1 id=\"About-Me\"><a href=\"#About-Me\" class=\"headerlink\" title=\"About Me\"></a>About Me</h1><p>My name is Haotian Wu(吴昊天). I’m a master student in <a href=\"http://cse.seu.edu.cn/en/index.html\">School of Computer Science &amp; Engineering</a> at <a href=\"http://www.seu.edu.cn/english/main.htm\">Southeast University</a> and will graduate in Summer 2018.</p>\n<ul>\n<li>Research Interests:<ul>\n<li>Web Crawler</li>\n<li>Data Mining &amp; Visualization</li>\n<li>Ad Hoc Networks</li>\n</ul>\n</li>\n<li>Sports: <ul>\n<li>Badminton</li>\n<li>Swimming</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h1><p>Just to avoid spams, here is the Base64 code of my e-mail address:<br><code>aGFvdGlhbnd1c2V1QGdtYWlsLmNvbQ==</code></p>\n"},{"title":"tags","date":"2016-06-11T13:57:52.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2016-06-11 21:57:52\ntype: \"tags\"\ncomments: false\n---\n","updated":"2016-06-17T01:05:57.735Z","path":"tags/index.html","layout":"page","_id":"ciquyzdjd0018ewc5glke7u23","content":"","excerpt":"","more":""},{"title":"categories","date":"2016-06-11T13:59:08.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2016-06-11 21:59:08\ntype: \"categories\"\ncomments: false\n---\n","updated":"2016-06-17T01:05:57.734Z","path":"categories/index.html","layout":"page","_id":"ciquyzdji0019ewc53t8j383i","content":"","excerpt":"","more":""}],"Post":[{"title":"CentOS 6.5 下scrapy与ghost.py的安装干货","date":"2016-06-16T05:34:08.000Z","comments":1,"_content":"之前一直在做Scrapy中关于网页动态内容的获取，主要目标是想获得javascript渲染后的网页html源码。\n在转向使用ghost.py来做脚本解析之前的挖坑爬坑过程中，我已经造访过我所知的大大小小各种论坛、博客以及贴吧和知乎。其中有大方向上指导意义的有知乎里的相关问题：\n* [Python 爬虫如何获取 JS 生成的 URL 和网页内容？](https://www.zhihu.com/question/21471960)\n* [Python爬虫在处理由Javascript动态生成的页面时有哪些解决方案？](https://www.zhihu.com/question/36450326)\n\n一些前人的技术博客如：\n* 开源中国上[斑ban](http://my.oschina.net/u/1024140?ft=blog)的[《使用python，scrapy写（定制）爬虫的经验，资料，杂》](http://my.oschina.net/u/1024140/blog/188154)。\n这篇博客里的总结涉及到爬虫的很多方面，看后受益匪浅，作者乃真大神，有很丰富的爬虫经验。\n\n上述几个干货里提到的方法，我基本都去了解了一下，也照着其中的几个方向挖过坑，过些时间我把我在这方面爬的所有坑都总结到一篇博客里。\n\nghost.py算是我掉坑里时间最长的，也是差点就成功的一个，到现在也弃了，弃的原因日后再说。其实，用ghost.py是在PyQt4的基础上转过去的，ghost.py是对**PyQt4**或者**PySide**的一个封装，需要安装其中一个才能运行。\n\n# PySide\n当然挖坑的第一步就是安装环境了，win7上安装简便得多，但到linux下就没那么舒服了。\n下面是我在CentOS 6.5和python2.7.11的环境上安装Scrapy、PySide和Ghost.py过程中查到的有用资料的整合。如嫌下面的字太小，可戳此PDF[源地址](http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf)。\n{% pdf http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf %}\n上面的PDF里ghost.py用的是PySide。PySide和PyQt4的功能和API近乎一致，我的理解是：PyQt4是PySide的商业化版本，两者都是Qt进行维护。\n\n# PyQt4\n我曾经在用PySide的时候遇到无法解决的Core Dump的bug，想转去试一下PyQt4看会不会好点，虽然结果是bug更频繁，但我还是列出安装PyQt4的一些小tips吧，希望后来人少走点弯路。\n\n安装PyQt4之前是需要安装**SIP**的。SIP是一个自动为C和C++库生成Python扩展模块的工具。为了方便开发PyQt，SIP于1998被“Riverbank Computing”公司创造出来。不过，SIP不专用于PyQt，而是适用于所有的C和C++库。但据说好像现在只有PyQt一直在坚持用SIP，很多别人家的项目在需要对C或C++封装调用的时候都用SWIG了。\n\n在安装过程中最让人抓狂的SIP和PyQt4的版本对应问题：某个固定版本的SIP只能支持少数几个版本的PyQt，有比较麻烦的兼容性问题。曾经在安装时，要么提示SIP版本过高，PyQt无法编译；要么PyQt版本过高，SIP不能支持。\n贴一个能够成功安装的博客链接：[CentOS7.1下python2.7.10安装PyQt4](http://blog.csdn.net/dgatiger/article/details/50331361)\n\n文中SIP的安装代码：\n```sh\nwget http://downloads.sourceforge.net/project/pyqt/sip/sip-4.17/sip-4.17.tar.gz\ntar xvf sip-4.17.tar.gz\ncd sip-4.17\npython configure.py\nmake & make install & make clean\n```\nPyQt的安装代码：\n```sh\nwget http://downloads.sourceforge.net/project/pyqt/PyQt4/PyQt-4.11.4/PyQt-x11-gpl-4.11.4.tar.gz\ntar xvf PyQt-x11-gpl-4.11.4.tar.gz\ncd PyQt-x11-gpl-4.11.4\npython configure.py -q  /usr/lib64/qt4/bin/qmake\nmake & make install & make clean\n```\n这篇博客里用的是**sip-4.17**和**PyQt-4.11.4**是能够成功的一对版本。另外，Python2.7最高只能支持到PyQt4，PyQt5好像需要Python3.X的环境；同时Python2与Python3的兼容性也较差。所以为了避免版本上的麻烦，个人建议Python2还是老老实实用PyQt4，Python3的也使用对应的PyQt5。\n","source":"_posts/centos-scrapy-ghost.py.md","raw":"title: CentOS 6.5 下scrapy与ghost.py的安装干货\ndate: 2016-06-16 13:34:08\ncomments: true\ntags: \n - CentOS\n - Scrapy\n - ghost.py\n - python\ncategories: Reviews\n---\n之前一直在做Scrapy中关于网页动态内容的获取，主要目标是想获得javascript渲染后的网页html源码。\n在转向使用ghost.py来做脚本解析之前的挖坑爬坑过程中，我已经造访过我所知的大大小小各种论坛、博客以及贴吧和知乎。其中有大方向上指导意义的有知乎里的相关问题：\n* [Python 爬虫如何获取 JS 生成的 URL 和网页内容？](https://www.zhihu.com/question/21471960)\n* [Python爬虫在处理由Javascript动态生成的页面时有哪些解决方案？](https://www.zhihu.com/question/36450326)\n\n一些前人的技术博客如：\n* 开源中国上[斑ban](http://my.oschina.net/u/1024140?ft=blog)的[《使用python，scrapy写（定制）爬虫的经验，资料，杂》](http://my.oschina.net/u/1024140/blog/188154)。\n这篇博客里的总结涉及到爬虫的很多方面，看后受益匪浅，作者乃真大神，有很丰富的爬虫经验。\n\n上述几个干货里提到的方法，我基本都去了解了一下，也照着其中的几个方向挖过坑，过些时间我把我在这方面爬的所有坑都总结到一篇博客里。\n\nghost.py算是我掉坑里时间最长的，也是差点就成功的一个，到现在也弃了，弃的原因日后再说。其实，用ghost.py是在PyQt4的基础上转过去的，ghost.py是对**PyQt4**或者**PySide**的一个封装，需要安装其中一个才能运行。\n\n# PySide\n当然挖坑的第一步就是安装环境了，win7上安装简便得多，但到linux下就没那么舒服了。\n下面是我在CentOS 6.5和python2.7.11的环境上安装Scrapy、PySide和Ghost.py过程中查到的有用资料的整合。如嫌下面的字太小，可戳此PDF[源地址](http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf)。\n{% pdf http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf %}\n上面的PDF里ghost.py用的是PySide。PySide和PyQt4的功能和API近乎一致，我的理解是：PyQt4是PySide的商业化版本，两者都是Qt进行维护。\n\n# PyQt4\n我曾经在用PySide的时候遇到无法解决的Core Dump的bug，想转去试一下PyQt4看会不会好点，虽然结果是bug更频繁，但我还是列出安装PyQt4的一些小tips吧，希望后来人少走点弯路。\n\n安装PyQt4之前是需要安装**SIP**的。SIP是一个自动为C和C++库生成Python扩展模块的工具。为了方便开发PyQt，SIP于1998被“Riverbank Computing”公司创造出来。不过，SIP不专用于PyQt，而是适用于所有的C和C++库。但据说好像现在只有PyQt一直在坚持用SIP，很多别人家的项目在需要对C或C++封装调用的时候都用SWIG了。\n\n在安装过程中最让人抓狂的SIP和PyQt4的版本对应问题：某个固定版本的SIP只能支持少数几个版本的PyQt，有比较麻烦的兼容性问题。曾经在安装时，要么提示SIP版本过高，PyQt无法编译；要么PyQt版本过高，SIP不能支持。\n贴一个能够成功安装的博客链接：[CentOS7.1下python2.7.10安装PyQt4](http://blog.csdn.net/dgatiger/article/details/50331361)\n\n文中SIP的安装代码：\n```sh\nwget http://downloads.sourceforge.net/project/pyqt/sip/sip-4.17/sip-4.17.tar.gz\ntar xvf sip-4.17.tar.gz\ncd sip-4.17\npython configure.py\nmake & make install & make clean\n```\nPyQt的安装代码：\n```sh\nwget http://downloads.sourceforge.net/project/pyqt/PyQt4/PyQt-4.11.4/PyQt-x11-gpl-4.11.4.tar.gz\ntar xvf PyQt-x11-gpl-4.11.4.tar.gz\ncd PyQt-x11-gpl-4.11.4\npython configure.py -q  /usr/lib64/qt4/bin/qmake\nmake & make install & make clean\n```\n这篇博客里用的是**sip-4.17**和**PyQt-4.11.4**是能够成功的一对版本。另外，Python2.7最高只能支持到PyQt4，PyQt5好像需要Python3.X的环境；同时Python2与Python3的兼容性也较差。所以为了避免版本上的麻烦，个人建议Python2还是老老实实用PyQt4，Python3的也使用对应的PyQt5。\n","slug":"centos-scrapy-ghost.py","published":1,"updated":"2016-07-13T12:02:54.373Z","layout":"post","photos":[],"link":"","_id":"ciquyzdfx0000ewc5430daxh2","content":"<p>之前一直在做Scrapy中关于网页动态内容的获取，主要目标是想获得javascript渲染后的网页html源码。<br>在转向使用ghost.py来做脚本解析之前的挖坑爬坑过程中，我已经造访过我所知的大大小小各种论坛、博客以及贴吧和知乎。其中有大方向上指导意义的有知乎里的相关问题：</p>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/21471960\" target=\"_blank\" rel=\"external\">Python 爬虫如何获取 JS 生成的 URL 和网页内容？</a></li>\n<li><a href=\"https://www.zhihu.com/question/36450326\" target=\"_blank\" rel=\"external\">Python爬虫在处理由Javascript动态生成的页面时有哪些解决方案？</a></li>\n</ul>\n<p>一些前人的技术博客如：</p>\n<ul>\n<li>开源中国上<a href=\"http://my.oschina.net/u/1024140?ft=blog\" target=\"_blank\" rel=\"external\">斑ban</a>的<a href=\"http://my.oschina.net/u/1024140/blog/188154\" target=\"_blank\" rel=\"external\">《使用python，scrapy写（定制）爬虫的经验，资料，杂》</a>。<br>这篇博客里的总结涉及到爬虫的很多方面，看后受益匪浅，作者乃真大神，有很丰富的爬虫经验。</li>\n</ul>\n<p>上述几个干货里提到的方法，我基本都去了解了一下，也照着其中的几个方向挖过坑，过些时间我把我在这方面爬的所有坑都总结到一篇博客里。</p>\n<p>ghost.py算是我掉坑里时间最长的，也是差点就成功的一个，到现在也弃了，弃的原因日后再说。其实，用ghost.py是在PyQt4的基础上转过去的，ghost.py是对<strong>PyQt4</strong>或者<strong>PySide</strong>的一个封装，需要安装其中一个才能运行。</p>\n<h1 id=\"PySide\"><a href=\"#PySide\" class=\"headerlink\" title=\"PySide\"></a>PySide</h1><p>当然挖坑的第一步就是安装环境了，win7上安装简便得多，但到linux下就没那么舒服了。<br>下面是我在CentOS 6.5和python2.7.11的环境上安装Scrapy、PySide和Ghost.py过程中查到的有用资料的整合。如嫌下面的字太小，可戳此PDF<a href=\"http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf\">源地址</a>。<br>\n\n\t<div class=\"row\">\n\t  <iframe src=\"http://nagland.github.io/viewer/web/viewer.html?val=http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf\" style=\"width:100%; height:900px\"></iframe>\n\t</div>\n\n\n<br>上面的PDF里ghost.py用的是PySide。PySide和PyQt4的功能和API近乎一致，我的理解是：PyQt4是PySide的商业化版本，两者都是Qt进行维护。</p>\n<h1 id=\"PyQt4\"><a href=\"#PyQt4\" class=\"headerlink\" title=\"PyQt4\"></a>PyQt4</h1><p>我曾经在用PySide的时候遇到无法解决的Core Dump的bug，想转去试一下PyQt4看会不会好点，虽然结果是bug更频繁，但我还是列出安装PyQt4的一些小tips吧，希望后来人少走点弯路。</p>\n<p>安装PyQt4之前是需要安装<strong>SIP</strong>的。SIP是一个自动为C和C++库生成Python扩展模块的工具。为了方便开发PyQt，SIP于1998被“Riverbank Computing”公司创造出来。不过，SIP不专用于PyQt，而是适用于所有的C和C++库。但据说好像现在只有PyQt一直在坚持用SIP，很多别人家的项目在需要对C或C++封装调用的时候都用SWIG了。</p>\n<p>在安装过程中最让人抓狂的SIP和PyQt4的版本对应问题：某个固定版本的SIP只能支持少数几个版本的PyQt，有比较麻烦的兼容性问题。曾经在安装时，要么提示SIP版本过高，PyQt无法编译；要么PyQt版本过高，SIP不能支持。<br>贴一个能够成功安装的博客链接：<a href=\"http://blog.csdn.net/dgatiger/article/details/50331361\" target=\"_blank\" rel=\"external\">CentOS7.1下python2.7.10安装PyQt4</a></p>\n<p>文中SIP的安装代码：<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://downloads.sourceforge.net/project/pyqt/sip/sip-4.17/sip-4.17.tar.gz</span><br><span class=\"line\">tar xvf sip-4.17.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> sip-4.17</span><br><span class=\"line\">python configure.py</span><br><span class=\"line\">make &amp; make install &amp; make clean</span><br></pre></td></tr></table></figure></p>\n<p>PyQt的安装代码：<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://downloads.sourceforge.net/project/pyqt/PyQt4/PyQt-4.11.4/PyQt-x11-gpl-4.11.4.tar.gz</span><br><span class=\"line\">tar xvf PyQt-x11-gpl-4.11.4.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> PyQt-x11-gpl-4.11.4</span><br><span class=\"line\">python configure.py -q  /usr/lib64/qt4/bin/qmake</span><br><span class=\"line\">make &amp; make install &amp; make clean</span><br></pre></td></tr></table></figure></p>\n<p>这篇博客里用的是<strong>sip-4.17</strong>和<strong>PyQt-4.11.4</strong>是能够成功的一对版本。另外，Python2.7最高只能支持到PyQt4，PyQt5好像需要Python3.X的环境；同时Python2与Python3的兼容性也较差。所以为了避免版本上的麻烦，个人建议Python2还是老老实实用PyQt4，Python3的也使用对应的PyQt5。</p>\n","excerpt":"","more":"<p>之前一直在做Scrapy中关于网页动态内容的获取，主要目标是想获得javascript渲染后的网页html源码。<br>在转向使用ghost.py来做脚本解析之前的挖坑爬坑过程中，我已经造访过我所知的大大小小各种论坛、博客以及贴吧和知乎。其中有大方向上指导意义的有知乎里的相关问题：</p>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/21471960\">Python 爬虫如何获取 JS 生成的 URL 和网页内容？</a></li>\n<li><a href=\"https://www.zhihu.com/question/36450326\">Python爬虫在处理由Javascript动态生成的页面时有哪些解决方案？</a></li>\n</ul>\n<p>一些前人的技术博客如：</p>\n<ul>\n<li>开源中国上<a href=\"http://my.oschina.net/u/1024140?ft=blog\">斑ban</a>的<a href=\"http://my.oschina.net/u/1024140/blog/188154\">《使用python，scrapy写（定制）爬虫的经验，资料，杂》</a>。<br>这篇博客里的总结涉及到爬虫的很多方面，看后受益匪浅，作者乃真大神，有很丰富的爬虫经验。</li>\n</ul>\n<p>上述几个干货里提到的方法，我基本都去了解了一下，也照着其中的几个方向挖过坑，过些时间我把我在这方面爬的所有坑都总结到一篇博客里。</p>\n<p>ghost.py算是我掉坑里时间最长的，也是差点就成功的一个，到现在也弃了，弃的原因日后再说。其实，用ghost.py是在PyQt4的基础上转过去的，ghost.py是对<strong>PyQt4</strong>或者<strong>PySide</strong>的一个封装，需要安装其中一个才能运行。</p>\n<h1 id=\"PySide\"><a href=\"#PySide\" class=\"headerlink\" title=\"PySide\"></a>PySide</h1><p>当然挖坑的第一步就是安装环境了，win7上安装简便得多，但到linux下就没那么舒服了。<br>下面是我在CentOS 6.5和python2.7.11的环境上安装Scrapy、PySide和Ghost.py过程中查到的有用资料的整合。如嫌下面的字太小，可戳此PDF<a href=\"http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf\">源地址</a>。<br>\n\n\t<div class=\"row\">\n\t  <iframe src=\"http://nagland.github.io/viewer/web/viewer.html?val=http://tripleday.github.io/uploads/pdf/CentOS-scrapy-ghost.py.pdf\" style=\"width:100%; height:900px\"></iframe>\n\t</div>\n\n\n<br>上面的PDF里ghost.py用的是PySide。PySide和PyQt4的功能和API近乎一致，我的理解是：PyQt4是PySide的商业化版本，两者都是Qt进行维护。</p>\n<h1 id=\"PyQt4\"><a href=\"#PyQt4\" class=\"headerlink\" title=\"PyQt4\"></a>PyQt4</h1><p>我曾经在用PySide的时候遇到无法解决的Core Dump的bug，想转去试一下PyQt4看会不会好点，虽然结果是bug更频繁，但我还是列出安装PyQt4的一些小tips吧，希望后来人少走点弯路。</p>\n<p>安装PyQt4之前是需要安装<strong>SIP</strong>的。SIP是一个自动为C和C++库生成Python扩展模块的工具。为了方便开发PyQt，SIP于1998被“Riverbank Computing”公司创造出来。不过，SIP不专用于PyQt，而是适用于所有的C和C++库。但据说好像现在只有PyQt一直在坚持用SIP，很多别人家的项目在需要对C或C++封装调用的时候都用SWIG了。</p>\n<p>在安装过程中最让人抓狂的SIP和PyQt4的版本对应问题：某个固定版本的SIP只能支持少数几个版本的PyQt，有比较麻烦的兼容性问题。曾经在安装时，要么提示SIP版本过高，PyQt无法编译；要么PyQt版本过高，SIP不能支持。<br>贴一个能够成功安装的博客链接：<a href=\"http://blog.csdn.net/dgatiger/article/details/50331361\">CentOS7.1下python2.7.10安装PyQt4</a></p>\n<p>文中SIP的安装代码：<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://downloads.sourceforge.net/project/pyqt/sip/sip-4.17/sip-4.17.tar.gz</span><br><span class=\"line\">tar xvf sip-4.17.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> sip-4.17</span><br><span class=\"line\">python configure.py</span><br><span class=\"line\">make &amp; make install &amp; make clean</span><br></pre></td></tr></table></figure></p>\n<p>PyQt的安装代码：<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://downloads.sourceforge.net/project/pyqt/PyQt4/PyQt-4.11.4/PyQt-x11-gpl-4.11.4.tar.gz</span><br><span class=\"line\">tar xvf PyQt-x11-gpl-4.11.4.tar.gz</span><br><span class=\"line\"><span class=\"built_in\">cd</span> PyQt-x11-gpl-4.11.4</span><br><span class=\"line\">python configure.py -q  /usr/lib64/qt4/bin/qmake</span><br><span class=\"line\">make &amp; make install &amp; make clean</span><br></pre></td></tr></table></figure></p>\n<p>这篇博客里用的是<strong>sip-4.17</strong>和<strong>PyQt-4.11.4</strong>是能够成功的一对版本。另外，Python2.7最高只能支持到PyQt4，PyQt5好像需要Python3.X的环境；同时Python2与Python3的兼容性也较差。所以为了避免版本上的麻烦，个人建议Python2还是老老实实用PyQt4，Python3的也使用对应的PyQt5。</p>\n"},{"title":"Hello World","date":"2016-06-12T13:28:52.000Z","comments":1,"photos":["/uploads/img/20160612/cover.gif"],"_content":"\nThis is my **first blog** after I established this site using [Hexo](https://hexo.io/) and [random](https://github.com/stiekel/hexo-theme-random). \nHere are some tests for Hexo:\n\n# Code Test:\n```javascript\n$ hexo clean\n$ hexo generate\n$ hexo server\n$ hexo deploy\n```\n# Mathjax Test:\n$$\\sum_{i=1}^n a_i=0$$\n\n$$\n\\begin{eqnarray}\nf(x_1,x_2,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2\n\\end{eqnarray}\n$$ \n\n$$\n\\begin{eqnarray}\n\\nabla\\cdot\\vec{E} &=& \\frac{\\rho}{\\epsilon_0} \\\\\n\\nabla\\cdot\\vec{B} &=& 0 \\\\\n\\nabla\\times\\vec{E} &=& -\\frac{\\partial B}{\\partial t} \\\\\n\\nabla\\times\\vec{B} &=& \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)\n\\end{eqnarray}\n$$\n\n# PDF Test:\n{% pdf http://tripleday.github.io/uploads/pdf/Clean%20Code.pdf %}\n\n# iFrame Test:\n{% iframe http://www.seu.edu.cn/english/main.htm 100% 500 %}\n\n# Picture Test:\n![Facebook](/uploads/img/20160612/facebook.jpg)\n\n# Youtube Test:\n{% youtube https://youtu.be/QBJxGklvHRg %}\n\n# Youku Test:\n{% youku 480 %}\nXMTU3NjExOTUwMA==\n{% endyouku %}\n\n","source":"_posts/hello-world.md","raw":"title: Hello World\ndate: 2016-06-12 21:28:52\ncomments: true\ntags: \n - English\n - Hexo\ncategories: Site Est\nphotos: \n - /uploads/img/20160612/cover.gif\n---\n\nThis is my **first blog** after I established this site using [Hexo](https://hexo.io/) and [random](https://github.com/stiekel/hexo-theme-random). \nHere are some tests for Hexo:\n\n# Code Test:\n```javascript\n$ hexo clean\n$ hexo generate\n$ hexo server\n$ hexo deploy\n```\n# Mathjax Test:\n$$\\sum_{i=1}^n a_i=0$$\n\n$$\n\\begin{eqnarray}\nf(x_1,x_2,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2\n\\end{eqnarray}\n$$ \n\n$$\n\\begin{eqnarray}\n\\nabla\\cdot\\vec{E} &=& \\frac{\\rho}{\\epsilon_0} \\\\\n\\nabla\\cdot\\vec{B} &=& 0 \\\\\n\\nabla\\times\\vec{E} &=& -\\frac{\\partial B}{\\partial t} \\\\\n\\nabla\\times\\vec{B} &=& \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)\n\\end{eqnarray}\n$$\n\n# PDF Test:\n{% pdf http://tripleday.github.io/uploads/pdf/Clean%20Code.pdf %}\n\n# iFrame Test:\n{% iframe http://www.seu.edu.cn/english/main.htm 100% 500 %}\n\n# Picture Test:\n![Facebook](/uploads/img/20160612/facebook.jpg)\n\n# Youtube Test:\n{% youtube https://youtu.be/QBJxGklvHRg %}\n\n# Youku Test:\n{% youku 480 %}\nXMTU3NjExOTUwMA==\n{% endyouku %}\n\n","slug":"hello-world","published":1,"updated":"2016-07-15T06:56:38.880Z","layout":"post","link":"","_id":"ciquyzdga0001ewc50hml7mkw","content":"<p>This is my <strong>first blog</strong> after I established this site using <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a> and <a href=\"https://github.com/stiekel/hexo-theme-random\" target=\"_blank\" rel=\"external\">random</a>.<br>Here are some tests for Hexo:</p>\n<h1 id=\"Code-Test\"><a href=\"#Code-Test\" class=\"headerlink\" title=\"Code Test:\"></a>Code Test:</h1><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo clean</span><br><span class=\"line\">$ hexo generate</span><br><span class=\"line\">$ hexo server</span><br><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<h1 id=\"Mathjax-Test\"><a href=\"#Mathjax-Test\" class=\"headerlink\" title=\"Mathjax Test:\"></a>Mathjax Test:</h1><p>$$\\sum_{i=1}^n a_i=0$$</p>\n<p>$$<br>\\begin{eqnarray}<br>f(x_1,x_2,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2<br>\\end{eqnarray}<br>$$ </p>\n<p>$$<br>\\begin{eqnarray}<br>\\nabla\\cdot\\vec{E} &amp;=&amp; \\frac{\\rho}{\\epsilon_0} \\\\<br>\\nabla\\cdot\\vec{B} &amp;=&amp; 0 \\\\<br>\\nabla\\times\\vec{E} &amp;=&amp; -\\frac{\\partial B}{\\partial t} \\\\<br>\\nabla\\times\\vec{B} &amp;=&amp; \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)<br>\\end{eqnarray}<br>$$</p>\n<h1 id=\"PDF-Test\"><a href=\"#PDF-Test\" class=\"headerlink\" title=\"PDF Test:\"></a>PDF Test:</h1>\n\n\t<div class=\"row\">\n\t  <iframe src=\"http://nagland.github.io/viewer/web/viewer.html?val=http://tripleday.github.io/uploads/pdf/Clean%20Code.pdf\" style=\"width:100%; height:900px\"></iframe>\n\t</div>\n\n\n\n<h1 id=\"iFrame-Test\"><a href=\"#iFrame-Test\" class=\"headerlink\" title=\"iFrame Test:\"></a>iFrame Test:</h1><iframe src=\"http://www.seu.edu.cn/english/main.htm\" width=\"100%\" height=\"500\" frameborder=\"0\" allowfullscreen></iframe>\n<h1 id=\"Picture-Test\"><a href=\"#Picture-Test\" class=\"headerlink\" title=\"Picture Test:\"></a>Picture Test:</h1><p><img src=\"/uploads/img/20160612/facebook.jpg\" alt=\"Facebook\"></p>\n<h1 id=\"Youtube-Test\"><a href=\"#Youtube-Test\" class=\"headerlink\" title=\"Youtube Test:\"></a>Youtube Test:</h1><div class=\"video-container\"><iframe src=\"//www.youtube.com/embed/https://youtu.be/QBJxGklvHRg\" frameborder=\"0\" allowfullscreen></iframe></div>\n<h1 id=\"Youku-Test\"><a href=\"#Youku-Test\" class=\"headerlink\" title=\"Youku Test:\"></a>Youku Test:</h1><div class=\"video-container\"><iframe height=\"480\" width=\"100%\" src=\"http://player.youku.com/embed/XMTU3NjExOTUwMA==\" frameborder=\"0\" allowfullscreen></iframe></div>\n","excerpt":"","more":"<p>This is my <strong>first blog</strong> after I established this site using <a href=\"https://hexo.io/\">Hexo</a> and <a href=\"https://github.com/stiekel/hexo-theme-random\">random</a>.<br>Here are some tests for Hexo:</p>\n<h1 id=\"Code-Test\"><a href=\"#Code-Test\" class=\"headerlink\" title=\"Code Test:\"></a>Code Test:</h1><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo clean</span><br><span class=\"line\">$ hexo generate</span><br><span class=\"line\">$ hexo server</span><br><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<h1 id=\"Mathjax-Test\"><a href=\"#Mathjax-Test\" class=\"headerlink\" title=\"Mathjax Test:\"></a>Mathjax Test:</h1><p>$$\\sum_{i=1}^n a_i=0$$</p>\n<p>$$<br>\\begin{eqnarray}<br>f(x_1,x_2,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2<br>\\end{eqnarray}<br>$$ </p>\n<p>$$<br>\\begin{eqnarray}<br>\\nabla\\cdot\\vec{E} &amp;=&amp; \\frac{\\rho}{\\epsilon_0} \\\\<br>\\nabla\\cdot\\vec{B} &amp;=&amp; 0 \\\\<br>\\nabla\\times\\vec{E} &amp;=&amp; -\\frac{\\partial B}{\\partial t} \\\\<br>\\nabla\\times\\vec{B} &amp;=&amp; \\mu_0\\left(\\vec{J}+\\epsilon_0\\frac{\\partial E}{\\partial t} \\right)<br>\\end{eqnarray}<br>$$</p>\n<h1 id=\"PDF-Test\"><a href=\"#PDF-Test\" class=\"headerlink\" title=\"PDF Test:\"></a>PDF Test:</h1>\n\n\t<div class=\"row\">\n\t  <iframe src=\"http://nagland.github.io/viewer/web/viewer.html?val=http://tripleday.github.io/uploads/pdf/Clean%20Code.pdf\" style=\"width:100%; height:900px\"></iframe>\n\t</div>\n\n\n\n<h1 id=\"iFrame-Test\"><a href=\"#iFrame-Test\" class=\"headerlink\" title=\"iFrame Test:\"></a>iFrame Test:</h1><iframe src=\"http://www.seu.edu.cn/english/main.htm\" width=\"100%\" height=\"500\" frameborder=\"0\" allowfullscreen></iframe>\n<h1 id=\"Picture-Test\"><a href=\"#Picture-Test\" class=\"headerlink\" title=\"Picture Test:\"></a>Picture Test:</h1><p><img src=\"/uploads/img/20160612/facebook.jpg\" alt=\"Facebook\"></p>\n<h1 id=\"Youtube-Test\"><a href=\"#Youtube-Test\" class=\"headerlink\" title=\"Youtube Test:\"></a>Youtube Test:</h1><div class=\"video-container\"><iframe src=\"//www.youtube.com/embed/https://youtu.be/QBJxGklvHRg\" frameborder=\"0\" allowfullscreen></iframe></div>\n<h1 id=\"Youku-Test\"><a href=\"#Youku-Test\" class=\"headerlink\" title=\"Youku Test:\"></a>Youku Test:</h1><div class=\"video-container\"><iframe height=480 width=100% src=\"http://player.youku.com/embed/XMTU3NjExOTUwMA==\" frameborder=0 allowfullscreen></iframe></div>\n"},{"title":"HMM、MEMM和CRF的学习与总结","date":"2016-07-14T08:03:45.000Z","comments":1,"photos":["/uploads/img/20160714/cover.png"],"_content":"最近一直在学习NLP里最基础的几个语言模型：**隐马尔科夫模型**（Hidden Markov Model，HMM）、**最大熵马尔科夫模型**（Maximum Entropy Markov Model，MEMM）和**条件随机场**（Conditional Random Field，CRF）。这三种模型在自然语言处理中，可以解决分词（segment，Seg）、标注（Tag）和命名实体识别（Named Entity Recognition，Ner）等问题。学习的时候参考最多的两本书是李航老师的**《统计学习方法》**和吴军老师的**《数学之美》**。如需这两本书的电子版可以给我留言。\n\n我先分别简单介绍一下几种模型，具体的推导过程就不列出来，《统计学习方法》上有非常详细的数学原理。\n\n# HMM\n\n下图是《统计学习方法》中的描述：\n![隐马尔科夫模型](/uploads/img/20160714/hmm.png)\nHMM模型将状态序列看作马尔可夫链，一阶马尔可夫链式针对相邻状态的关系进行建模，其中每个状态对应一个概率函数。HMM是一种**生成模型**（Generative Model），定义了联合概率分布 ，其中$x$和$y$分别表示观测序列和状态序列的随机变量。\n\n如果需要一些浅显简单的例子来理解HMM，下面的一个知乎问题和一篇博客可能有所帮助：\n- [如何用简单易懂的例子解释隐马尔可夫模型？](https://www.zhihu.com/question/20962240)\n- [隐马尔可夫模型（HMM）攻略](http://blog.csdn.net/likelet/article/details/7056068)\n\n# Maximum Entropy Model\n\n首先贴一下关于最大熵模型的定义：\n![最大熵模型](/uploads/img/20160714/me.png)\n最大熵模型的基本思想就是不要把所有鸡蛋放到一个篮子里。式（6.12）中的$f_i$是**特征函数**，代表各个约束条件。最大熵模型就是在符合所有约束条件下作出**最不偏倚**的假设，求得可使熵最大化的概率分布。熵最大，表示该系统内各随机事件(变量)发生的概率是近似均匀的，等可能性的。\n\n最大熵模型可以使用任意的复杂相关特征（即特征函数），在性能上最大熵分类器超过了Bayes分类器。但是，作为一种分类器模型，这两种方法有一个共同的缺点：每个词都是单独进行分类的，标记状态之间的关系无法得到充分利用，具有马尔可夫链的HMM模型可以建立标记之间的马尔可夫关联性，这是最大熵模型所没有的。\n\n最大熵模型的**优点**：首先，最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型;其次，最大熵统计模型可以灵活地设置约束条件，通过约束条件的多少可以调节模型对未知数据的适应度和对已知数据的拟合程度;再次，它还能自然地解决了统计模型中参数平滑的问题。\n\n最大熵模型的**不足**：首先，最大熵统计模型中二值化特征只是记录特征的出现是否，而文本分类需要知道特征的强度，因此，它在分类方法中不是最优的;其次，由于算法收敛的速度较慢，所以导致最大熵统计模型它的计算代价较大，时空开销大;再次，数据稀疏问题比较严重。\n\n# MEMM\n\n最大熵马尔科夫模型把HMM模型和Maximum Entropy模型的优点集合成一种**生成模型**（Generative Model），这个模型允许状态转移概率依赖于序列中彼此之间非独立的特征上，从而将上下文信息引入到模型的学习和识别过程中，提高了识别的精确度，召回率也大大的提高，有实验证明，这个新的模型在序列标注任务上表现的比HMM和无状态的最大熵模型要好得多。\n![最大熵马尔科夫模型](/uploads/img/20160714/memm.png)\n可以注意到MEMM在每个节点对所有可能的状态$y$求和然后用做局部归一化的分母。所以MEMM中节点状态转移的概率都是归一化的概率。\n\nHMM模型中存在两个假设：一是输出观察值之间严格独立，二是状态的转移过程中当前状态只与前一状态有关(一阶马尔可夫模型)。但MEMM模型克服了观察值之间严格独立产生的问题，但是由于状态之间的假设理论，使得该模型仍然存在**标注偏置问题**（Label Bias Problem）。\n\n关于标注偏置问题，网上最多的是下面这个例子解释：\n![](/uploads/img/20160714/label-bias-1.png)\n路径1-1-1-1的概率：0.4\\*0.45\\*0.5=0.09\n路径2-2-2-2的概率：0.018\n路径1-2-1-2的概率：0.06\n路径1-1-2-2的概率：0.066\n由此可得最优路径为：1-1-1-1\n![](/uploads/img/20160714/label-bias-2.png)\n而实际上，在上图中，状态1偏向于转移到状态2，而状态2总倾向于停留在状态2，这就是所谓的标注偏置问题，由于分支数不同，概率的分布不均衡，导致状态的转移存在不公平的情况。\n例子的出处参见[标注偏置问题(Label Bias Problem)和HMM、MEMM、CRF模型比较](http://blog.csdn.net/lskyne/article/details/8669301)\n\n# CRF\n\n![线性链条件随机场模型](/uploads/img/20160714/crf-1.png)\n这是书上关于条件随机场的简化形式。本文所提的CRF都不是广义上最大熵准则建模条件概率的条件随机场模型，而是约束在线性链上的特殊的条件随机场，称为线性链条件随机场（linear chain CRF）。CRF属于**判别模型**（Discrimitive Model）。\n![线性链条件随机场模型图示](/uploads/img/20160714/crf-2.png)\n上式中也同样有$f_i$**特征函数**。之前我对模型中的特征函数一直不太理解。大家可以参考[中文分词入门之字标注法4](http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%954)这篇文章。文章主要介绍借用条件随机场工具“[CRF++: Yet Another CRF toolkit](http://tenet.dl.sourceforge.net/project/crfpp/crfpp-win32/0.54/CRF%2B%2B-0.54.zip)”来完成字标注中文分词的全过程。其中提及了特征模板文件，它的特征提取可能包含了前后多个节点的观测序列。顺便推荐一下这个非常厉害的群体博客[52nlp](http://www.52nlp.cn/)。\n《数学之美》里“徐志摩喜欢林徽因”的例子也可供参考。\n\nCRF模型的**优点**：首先，CRF具有很强的推理能力，并且能够使用复杂、有重叠性和非独立的特征进行训练和推理，能够充分地利用上下文信息作为特征，还可以任意地添加其他外部特征，使得模型能够获取的信息非常丰富。其次，CRF的性能更好，CRF对特征的融合能力比较强，识别效果好于MEMM。\n\nCRF模型的**不足**：使用CRF方法的过程中，特征的选择和优化是影响结果的关键因素，特征选择问题的好与坏，直接决定了系统性能的高低。而且，CRF训练模型的时间较长，且获得的模型很大，在一般的PC机上无法运行。\n\n更多一些详细的CRF解释可以参考知乎的相关问题[如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？](https://www.zhihu.com/question/35866596)\n\n# MEMM与CRF区别\n\n上面的公式都是别人贴图里的，下面的公式是我走心地敲出来的，方便看出两者的差异。\n\nMEMM的公式表示如下：\n$$\n\\begin{eqnarray\\*}\np(y_1, \\ldots, y_T | x_1, \\ldots, x_T) &=& \\prod_{i=1}^T p(y_i | x_1, \\ldots, x_T, y_{i-1}) \\\\\np(y_i | x_1, \\ldots, x_T, y_{i-1}) &=&\n\\frac{exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y_i)}\n{\\sum\\limits_y exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y)}\n\\end{eqnarray\\*}\n$$\n线性链CRF的公式表示如下：\n$$\n\\begin{eqnarray\\*}\np(y|x) &=& \\frac{p(y, x)}{\\sum\\limits_Y p(y, x)}\n\\\\\n&=& \\frac{\\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x))}\n{\\sum\\limits_Y \\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x)) }\n\\end{eqnarray\\*}\n$$\n不同点：\n- 首先，CRF是**判别模型**，而MEMM我个人理解是**生成模型**。MEMM是在HMM基础上的优化，它保留了“状态的转移过程中当前状态只与前一状态有关”这一个独立性假设，状态与状态之间的转移仍是遵循一个**不大于1**的、只在同一结点作归一化的局部归一化概率，与HMM的思想相近。\n- MEMM和CRF的**归一化位置**不同。从上面的公式可以看出，MEMM是在given前一状态$y_{i-1}$的情况下，对下一个节点所有可能的$y_i$作局部的归一化，利用最大熵模型，从观测序列$x$和前一状态$y_{i-1}$中的特征学习到$y_i$的分布。而CRF是对$Y$中所有可能的状态序列作全局的归一化，假设每个节点有$L$中状态，序列中有$T$个节点，那么所有可能的状态序列数为$L^T$，这导致在模型学习时会较为复杂。\n- MEMM在用**viterbi算法**求解最优路径时，每次乘上的是个归一化概率，而CRF乘上的是一个自然指数，没有经过归一化。当遇到某些不公平的情况：某条路径自然指数本身很小，但归一化后变为一个很大的概率比如0.9，而同时即使别的路径自然指数很大，但它们竞争也激烈，归一化后的概率反而不大，这样前一条路径就会被选中，导致了之前提过的标记偏置问题，而CRF可以避免这一问题。\n\n关于MEMM和CRF两者的区别，推荐可以参考下面的一个知乎问题和一篇博客：\n- [MEMM和CRF有什么不同？](https://www.zhihu.com/question/30869789)\n- [统计模型之间的比较，HMM，最大熵模型，CRF条件随机场 ](http://blog.sina.com.cn/s/blog_8af106960102v0v1.html)\n\n# 写在最后\n\n关于用做封面的那张图，是对相关模型一个非常抽象、宏观的转换图，感觉非常精髓，出处为[An introduction to conditional random fields](http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf)。\n\n以上均为本小白个人理解，如有任何不当或者错误，欢迎指正。\n\n","source":"_posts/hmm-memm-crf.md","raw":"title: HMM、MEMM和CRF的学习与总结\ndate: 2016-07-14 16:03:45\ncomments: true\ntags: \n - HMM\n - MEMM\n - CRF\ncategories: NLP\nphotos: \n - /uploads/img/20160714/cover.png\n---\n最近一直在学习NLP里最基础的几个语言模型：**隐马尔科夫模型**（Hidden Markov Model，HMM）、**最大熵马尔科夫模型**（Maximum Entropy Markov Model，MEMM）和**条件随机场**（Conditional Random Field，CRF）。这三种模型在自然语言处理中，可以解决分词（segment，Seg）、标注（Tag）和命名实体识别（Named Entity Recognition，Ner）等问题。学习的时候参考最多的两本书是李航老师的**《统计学习方法》**和吴军老师的**《数学之美》**。如需这两本书的电子版可以给我留言。\n\n我先分别简单介绍一下几种模型，具体的推导过程就不列出来，《统计学习方法》上有非常详细的数学原理。\n\n# HMM\n\n下图是《统计学习方法》中的描述：\n![隐马尔科夫模型](/uploads/img/20160714/hmm.png)\nHMM模型将状态序列看作马尔可夫链，一阶马尔可夫链式针对相邻状态的关系进行建模，其中每个状态对应一个概率函数。HMM是一种**生成模型**（Generative Model），定义了联合概率分布 ，其中$x$和$y$分别表示观测序列和状态序列的随机变量。\n\n如果需要一些浅显简单的例子来理解HMM，下面的一个知乎问题和一篇博客可能有所帮助：\n- [如何用简单易懂的例子解释隐马尔可夫模型？](https://www.zhihu.com/question/20962240)\n- [隐马尔可夫模型（HMM）攻略](http://blog.csdn.net/likelet/article/details/7056068)\n\n# Maximum Entropy Model\n\n首先贴一下关于最大熵模型的定义：\n![最大熵模型](/uploads/img/20160714/me.png)\n最大熵模型的基本思想就是不要把所有鸡蛋放到一个篮子里。式（6.12）中的$f_i$是**特征函数**，代表各个约束条件。最大熵模型就是在符合所有约束条件下作出**最不偏倚**的假设，求得可使熵最大化的概率分布。熵最大，表示该系统内各随机事件(变量)发生的概率是近似均匀的，等可能性的。\n\n最大熵模型可以使用任意的复杂相关特征（即特征函数），在性能上最大熵分类器超过了Bayes分类器。但是，作为一种分类器模型，这两种方法有一个共同的缺点：每个词都是单独进行分类的，标记状态之间的关系无法得到充分利用，具有马尔可夫链的HMM模型可以建立标记之间的马尔可夫关联性，这是最大熵模型所没有的。\n\n最大熵模型的**优点**：首先，最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型;其次，最大熵统计模型可以灵活地设置约束条件，通过约束条件的多少可以调节模型对未知数据的适应度和对已知数据的拟合程度;再次，它还能自然地解决了统计模型中参数平滑的问题。\n\n最大熵模型的**不足**：首先，最大熵统计模型中二值化特征只是记录特征的出现是否，而文本分类需要知道特征的强度，因此，它在分类方法中不是最优的;其次，由于算法收敛的速度较慢，所以导致最大熵统计模型它的计算代价较大，时空开销大;再次，数据稀疏问题比较严重。\n\n# MEMM\n\n最大熵马尔科夫模型把HMM模型和Maximum Entropy模型的优点集合成一种**生成模型**（Generative Model），这个模型允许状态转移概率依赖于序列中彼此之间非独立的特征上，从而将上下文信息引入到模型的学习和识别过程中，提高了识别的精确度，召回率也大大的提高，有实验证明，这个新的模型在序列标注任务上表现的比HMM和无状态的最大熵模型要好得多。\n![最大熵马尔科夫模型](/uploads/img/20160714/memm.png)\n可以注意到MEMM在每个节点对所有可能的状态$y$求和然后用做局部归一化的分母。所以MEMM中节点状态转移的概率都是归一化的概率。\n\nHMM模型中存在两个假设：一是输出观察值之间严格独立，二是状态的转移过程中当前状态只与前一状态有关(一阶马尔可夫模型)。但MEMM模型克服了观察值之间严格独立产生的问题，但是由于状态之间的假设理论，使得该模型仍然存在**标注偏置问题**（Label Bias Problem）。\n\n关于标注偏置问题，网上最多的是下面这个例子解释：\n![](/uploads/img/20160714/label-bias-1.png)\n路径1-1-1-1的概率：0.4\\*0.45\\*0.5=0.09\n路径2-2-2-2的概率：0.018\n路径1-2-1-2的概率：0.06\n路径1-1-2-2的概率：0.066\n由此可得最优路径为：1-1-1-1\n![](/uploads/img/20160714/label-bias-2.png)\n而实际上，在上图中，状态1偏向于转移到状态2，而状态2总倾向于停留在状态2，这就是所谓的标注偏置问题，由于分支数不同，概率的分布不均衡，导致状态的转移存在不公平的情况。\n例子的出处参见[标注偏置问题(Label Bias Problem)和HMM、MEMM、CRF模型比较](http://blog.csdn.net/lskyne/article/details/8669301)\n\n# CRF\n\n![线性链条件随机场模型](/uploads/img/20160714/crf-1.png)\n这是书上关于条件随机场的简化形式。本文所提的CRF都不是广义上最大熵准则建模条件概率的条件随机场模型，而是约束在线性链上的特殊的条件随机场，称为线性链条件随机场（linear chain CRF）。CRF属于**判别模型**（Discrimitive Model）。\n![线性链条件随机场模型图示](/uploads/img/20160714/crf-2.png)\n上式中也同样有$f_i$**特征函数**。之前我对模型中的特征函数一直不太理解。大家可以参考[中文分词入门之字标注法4](http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%954)这篇文章。文章主要介绍借用条件随机场工具“[CRF++: Yet Another CRF toolkit](http://tenet.dl.sourceforge.net/project/crfpp/crfpp-win32/0.54/CRF%2B%2B-0.54.zip)”来完成字标注中文分词的全过程。其中提及了特征模板文件，它的特征提取可能包含了前后多个节点的观测序列。顺便推荐一下这个非常厉害的群体博客[52nlp](http://www.52nlp.cn/)。\n《数学之美》里“徐志摩喜欢林徽因”的例子也可供参考。\n\nCRF模型的**优点**：首先，CRF具有很强的推理能力，并且能够使用复杂、有重叠性和非独立的特征进行训练和推理，能够充分地利用上下文信息作为特征，还可以任意地添加其他外部特征，使得模型能够获取的信息非常丰富。其次，CRF的性能更好，CRF对特征的融合能力比较强，识别效果好于MEMM。\n\nCRF模型的**不足**：使用CRF方法的过程中，特征的选择和优化是影响结果的关键因素，特征选择问题的好与坏，直接决定了系统性能的高低。而且，CRF训练模型的时间较长，且获得的模型很大，在一般的PC机上无法运行。\n\n更多一些详细的CRF解释可以参考知乎的相关问题[如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？](https://www.zhihu.com/question/35866596)\n\n# MEMM与CRF区别\n\n上面的公式都是别人贴图里的，下面的公式是我走心地敲出来的，方便看出两者的差异。\n\nMEMM的公式表示如下：\n$$\n\\begin{eqnarray\\*}\np(y_1, \\ldots, y_T | x_1, \\ldots, x_T) &=& \\prod_{i=1}^T p(y_i | x_1, \\ldots, x_T, y_{i-1}) \\\\\np(y_i | x_1, \\ldots, x_T, y_{i-1}) &=&\n\\frac{exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y_i)}\n{\\sum\\limits_y exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y)}\n\\end{eqnarray\\*}\n$$\n线性链CRF的公式表示如下：\n$$\n\\begin{eqnarray\\*}\np(y|x) &=& \\frac{p(y, x)}{\\sum\\limits_Y p(y, x)}\n\\\\\n&=& \\frac{\\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x))}\n{\\sum\\limits_Y \\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x)) }\n\\end{eqnarray\\*}\n$$\n不同点：\n- 首先，CRF是**判别模型**，而MEMM我个人理解是**生成模型**。MEMM是在HMM基础上的优化，它保留了“状态的转移过程中当前状态只与前一状态有关”这一个独立性假设，状态与状态之间的转移仍是遵循一个**不大于1**的、只在同一结点作归一化的局部归一化概率，与HMM的思想相近。\n- MEMM和CRF的**归一化位置**不同。从上面的公式可以看出，MEMM是在given前一状态$y_{i-1}$的情况下，对下一个节点所有可能的$y_i$作局部的归一化，利用最大熵模型，从观测序列$x$和前一状态$y_{i-1}$中的特征学习到$y_i$的分布。而CRF是对$Y$中所有可能的状态序列作全局的归一化，假设每个节点有$L$中状态，序列中有$T$个节点，那么所有可能的状态序列数为$L^T$，这导致在模型学习时会较为复杂。\n- MEMM在用**viterbi算法**求解最优路径时，每次乘上的是个归一化概率，而CRF乘上的是一个自然指数，没有经过归一化。当遇到某些不公平的情况：某条路径自然指数本身很小，但归一化后变为一个很大的概率比如0.9，而同时即使别的路径自然指数很大，但它们竞争也激烈，归一化后的概率反而不大，这样前一条路径就会被选中，导致了之前提过的标记偏置问题，而CRF可以避免这一问题。\n\n关于MEMM和CRF两者的区别，推荐可以参考下面的一个知乎问题和一篇博客：\n- [MEMM和CRF有什么不同？](https://www.zhihu.com/question/30869789)\n- [统计模型之间的比较，HMM，最大熵模型，CRF条件随机场 ](http://blog.sina.com.cn/s/blog_8af106960102v0v1.html)\n\n# 写在最后\n\n关于用做封面的那张图，是对相关模型一个非常抽象、宏观的转换图，感觉非常精髓，出处为[An introduction to conditional random fields](http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf)。\n\n以上均为本小白个人理解，如有任何不当或者错误，欢迎指正。\n\n","slug":"hmm-memm-crf","published":1,"updated":"2016-07-16T11:49:43.107Z","layout":"post","link":"","_id":"ciquyzdgn0004ewc5yo7h7how","content":"<p>最近一直在学习NLP里最基础的几个语言模型：<strong>隐马尔科夫模型</strong>（Hidden Markov Model，HMM）、<strong>最大熵马尔科夫模型</strong>（Maximum Entropy Markov Model，MEMM）和<strong>条件随机场</strong>（Conditional Random Field，CRF）。这三种模型在自然语言处理中，可以解决分词（segment，Seg）、标注（Tag）和命名实体识别（Named Entity Recognition，Ner）等问题。学习的时候参考最多的两本书是李航老师的<strong>《统计学习方法》</strong>和吴军老师的<strong>《数学之美》</strong>。如需这两本书的电子版可以给我留言。</p>\n<p>我先分别简单介绍一下几种模型，具体的推导过程就不列出来，《统计学习方法》上有非常详细的数学原理。</p>\n<h1 id=\"HMM\"><a href=\"#HMM\" class=\"headerlink\" title=\"HMM\"></a>HMM</h1><p>下图是《统计学习方法》中的描述：<br><img src=\"/uploads/img/20160714/hmm.png\" alt=\"隐马尔科夫模型\"><br>HMM模型将状态序列看作马尔可夫链，一阶马尔可夫链式针对相邻状态的关系进行建模，其中每个状态对应一个概率函数。HMM是一种<strong>生成模型</strong>（Generative Model），定义了联合概率分布 ，其中$x$和$y$分别表示观测序列和状态序列的随机变量。</p>\n<p>如果需要一些浅显简单的例子来理解HMM，下面的一个知乎问题和一篇博客可能有所帮助：</p>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/20962240\" target=\"_blank\" rel=\"external\">如何用简单易懂的例子解释隐马尔可夫模型？</a></li>\n<li><a href=\"http://blog.csdn.net/likelet/article/details/7056068\" target=\"_blank\" rel=\"external\">隐马尔可夫模型（HMM）攻略</a></li>\n</ul>\n<h1 id=\"Maximum-Entropy-Model\"><a href=\"#Maximum-Entropy-Model\" class=\"headerlink\" title=\"Maximum Entropy Model\"></a>Maximum Entropy Model</h1><p>首先贴一下关于最大熵模型的定义：<br><img src=\"/uploads/img/20160714/me.png\" alt=\"最大熵模型\"><br>最大熵模型的基本思想就是不要把所有鸡蛋放到一个篮子里。式（6.12）中的$f_i$是<strong>特征函数</strong>，代表各个约束条件。最大熵模型就是在符合所有约束条件下作出<strong>最不偏倚</strong>的假设，求得可使熵最大化的概率分布。熵最大，表示该系统内各随机事件(变量)发生的概率是近似均匀的，等可能性的。</p>\n<p>最大熵模型可以使用任意的复杂相关特征（即特征函数），在性能上最大熵分类器超过了Bayes分类器。但是，作为一种分类器模型，这两种方法有一个共同的缺点：每个词都是单独进行分类的，标记状态之间的关系无法得到充分利用，具有马尔可夫链的HMM模型可以建立标记之间的马尔可夫关联性，这是最大熵模型所没有的。</p>\n<p>最大熵模型的<strong>优点</strong>：首先，最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型;其次，最大熵统计模型可以灵活地设置约束条件，通过约束条件的多少可以调节模型对未知数据的适应度和对已知数据的拟合程度;再次，它还能自然地解决了统计模型中参数平滑的问题。</p>\n<p>最大熵模型的<strong>不足</strong>：首先，最大熵统计模型中二值化特征只是记录特征的出现是否，而文本分类需要知道特征的强度，因此，它在分类方法中不是最优的;其次，由于算法收敛的速度较慢，所以导致最大熵统计模型它的计算代价较大，时空开销大;再次，数据稀疏问题比较严重。</p>\n<h1 id=\"MEMM\"><a href=\"#MEMM\" class=\"headerlink\" title=\"MEMM\"></a>MEMM</h1><p>最大熵马尔科夫模型把HMM模型和Maximum Entropy模型的优点集合成一种<strong>生成模型</strong>（Generative Model），这个模型允许状态转移概率依赖于序列中彼此之间非独立的特征上，从而将上下文信息引入到模型的学习和识别过程中，提高了识别的精确度，召回率也大大的提高，有实验证明，这个新的模型在序列标注任务上表现的比HMM和无状态的最大熵模型要好得多。<br><img src=\"/uploads/img/20160714/memm.png\" alt=\"最大熵马尔科夫模型\"><br>可以注意到MEMM在每个节点对所有可能的状态$y$求和然后用做局部归一化的分母。所以MEMM中节点状态转移的概率都是归一化的概率。</p>\n<p>HMM模型中存在两个假设：一是输出观察值之间严格独立，二是状态的转移过程中当前状态只与前一状态有关(一阶马尔可夫模型)。但MEMM模型克服了观察值之间严格独立产生的问题，但是由于状态之间的假设理论，使得该模型仍然存在<strong>标注偏置问题</strong>（Label Bias Problem）。</p>\n<p>关于标注偏置问题，网上最多的是下面这个例子解释：<br><img src=\"/uploads/img/20160714/label-bias-1.png\" alt=\"\"><br>路径1-1-1-1的概率：0.4*0.45*0.5=0.09<br>路径2-2-2-2的概率：0.018<br>路径1-2-1-2的概率：0.06<br>路径1-1-2-2的概率：0.066<br>由此可得最优路径为：1-1-1-1<br><img src=\"/uploads/img/20160714/label-bias-2.png\" alt=\"\"><br>而实际上，在上图中，状态1偏向于转移到状态2，而状态2总倾向于停留在状态2，这就是所谓的标注偏置问题，由于分支数不同，概率的分布不均衡，导致状态的转移存在不公平的情况。<br>例子的出处参见<a href=\"http://blog.csdn.net/lskyne/article/details/8669301\" target=\"_blank\" rel=\"external\">标注偏置问题(Label Bias Problem)和HMM、MEMM、CRF模型比较</a></p>\n<h1 id=\"CRF\"><a href=\"#CRF\" class=\"headerlink\" title=\"CRF\"></a>CRF</h1><p><img src=\"/uploads/img/20160714/crf-1.png\" alt=\"线性链条件随机场模型\"><br>这是书上关于条件随机场的简化形式。本文所提的CRF都不是广义上最大熵准则建模条件概率的条件随机场模型，而是约束在线性链上的特殊的条件随机场，称为线性链条件随机场（linear chain CRF）。CRF属于<strong>判别模型</strong>（Discrimitive Model）。<br><img src=\"/uploads/img/20160714/crf-2.png\" alt=\"线性链条件随机场模型图示\"><br>上式中也同样有$f_i$<strong>特征函数</strong>。之前我对模型中的特征函数一直不太理解。大家可以参考<a href=\"http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%954\" target=\"_blank\" rel=\"external\">中文分词入门之字标注法4</a>这篇文章。文章主要介绍借用条件随机场工具“<a href=\"http://tenet.dl.sourceforge.net/project/crfpp/crfpp-win32/0.54/CRF%2B%2B-0.54.zip\" target=\"_blank\" rel=\"external\">CRF++: Yet Another CRF toolkit</a>”来完成字标注中文分词的全过程。其中提及了特征模板文件，它的特征提取可能包含了前后多个节点的观测序列。顺便推荐一下这个非常厉害的群体博客<a href=\"http://www.52nlp.cn/\" target=\"_blank\" rel=\"external\">52nlp</a>。<br>《数学之美》里“徐志摩喜欢林徽因”的例子也可供参考。</p>\n<p>CRF模型的<strong>优点</strong>：首先，CRF具有很强的推理能力，并且能够使用复杂、有重叠性和非独立的特征进行训练和推理，能够充分地利用上下文信息作为特征，还可以任意地添加其他外部特征，使得模型能够获取的信息非常丰富。其次，CRF的性能更好，CRF对特征的融合能力比较强，识别效果好于MEMM。</p>\n<p>CRF模型的<strong>不足</strong>：使用CRF方法的过程中，特征的选择和优化是影响结果的关键因素，特征选择问题的好与坏，直接决定了系统性能的高低。而且，CRF训练模型的时间较长，且获得的模型很大，在一般的PC机上无法运行。</p>\n<p>更多一些详细的CRF解释可以参考知乎的相关问题<a href=\"https://www.zhihu.com/question/35866596\" target=\"_blank\" rel=\"external\">如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？</a></p>\n<h1 id=\"MEMM与CRF区别\"><a href=\"#MEMM与CRF区别\" class=\"headerlink\" title=\"MEMM与CRF区别\"></a>MEMM与CRF区别</h1><p>上面的公式都是别人贴图里的，下面的公式是我走心地敲出来的，方便看出两者的差异。</p>\n<p>MEMM的公式表示如下：<br>$$<br>\\begin{eqnarray*}<br>p(y_1, \\ldots, y_T | x_1, \\ldots, x_T) &amp;=&amp; \\prod_{i=1}^T p(y_i | x_1, \\ldots, x_T, y_{i-1}) \\\\<br>p(y_i | x_1, \\ldots, x_T, y_{i-1}) &amp;=&amp;<br>\\frac{exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y_i)}<br>{\\sum\\limits_y exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y)}<br>\\end{eqnarray*}<br>$$<br>线性链CRF的公式表示如下：<br>$$<br>\\begin{eqnarray*}<br>p(y|x) &amp;=&amp; \\frac{p(y, x)}{\\sum\\limits_Y p(y, x)}<br>\\\\<br>&amp;=&amp; \\frac{\\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x))}<br>{\\sum\\limits_Y \\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x)) }<br>\\end{eqnarray*}<br>$$<br>不同点：</p>\n<ul>\n<li>首先，CRF是<strong>判别模型</strong>，而MEMM我个人理解是<strong>生成模型</strong>。MEMM是在HMM基础上的优化，它保留了“状态的转移过程中当前状态只与前一状态有关”这一个独立性假设，状态与状态之间的转移仍是遵循一个<strong>不大于1</strong>的、只在同一结点作归一化的局部归一化概率，与HMM的思想相近。</li>\n<li>MEMM和CRF的<strong>归一化位置</strong>不同。从上面的公式可以看出，MEMM是在given前一状态$y_{i-1}$的情况下，对下一个节点所有可能的$y_i$作局部的归一化，利用最大熵模型，从观测序列$x$和前一状态$y_{i-1}$中的特征学习到$y_i$的分布。而CRF是对$Y$中所有可能的状态序列作全局的归一化，假设每个节点有$L$中状态，序列中有$T$个节点，那么所有可能的状态序列数为$L^T$，这导致在模型学习时会较为复杂。</li>\n<li>MEMM在用<strong>viterbi算法</strong>求解最优路径时，每次乘上的是个归一化概率，而CRF乘上的是一个自然指数，没有经过归一化。当遇到某些不公平的情况：某条路径自然指数本身很小，但归一化后变为一个很大的概率比如0.9，而同时即使别的路径自然指数很大，但它们竞争也激烈，归一化后的概率反而不大，这样前一条路径就会被选中，导致了之前提过的标记偏置问题，而CRF可以避免这一问题。</li>\n</ul>\n<p>关于MEMM和CRF两者的区别，推荐可以参考下面的一个知乎问题和一篇博客：</p>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/30869789\" target=\"_blank\" rel=\"external\">MEMM和CRF有什么不同？</a></li>\n<li><a href=\"http://blog.sina.com.cn/s/blog_8af106960102v0v1.html\" target=\"_blank\" rel=\"external\">统计模型之间的比较，HMM，最大熵模型，CRF条件随机场 </a></li>\n</ul>\n<h1 id=\"写在最后\"><a href=\"#写在最后\" class=\"headerlink\" title=\"写在最后\"></a>写在最后</h1><p>关于用做封面的那张图，是对相关模型一个非常抽象、宏观的转换图，感觉非常精髓，出处为<a href=\"http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf\" target=\"_blank\" rel=\"external\">An introduction to conditional random fields</a>。</p>\n<p>以上均为本小白个人理解，如有任何不当或者错误，欢迎指正。</p>\n","excerpt":"","more":"<p>最近一直在学习NLP里最基础的几个语言模型：<strong>隐马尔科夫模型</strong>（Hidden Markov Model，HMM）、<strong>最大熵马尔科夫模型</strong>（Maximum Entropy Markov Model，MEMM）和<strong>条件随机场</strong>（Conditional Random Field，CRF）。这三种模型在自然语言处理中，可以解决分词（segment，Seg）、标注（Tag）和命名实体识别（Named Entity Recognition，Ner）等问题。学习的时候参考最多的两本书是李航老师的<strong>《统计学习方法》</strong>和吴军老师的<strong>《数学之美》</strong>。如需这两本书的电子版可以给我留言。</p>\n<p>我先分别简单介绍一下几种模型，具体的推导过程就不列出来，《统计学习方法》上有非常详细的数学原理。</p>\n<h1 id=\"HMM\"><a href=\"#HMM\" class=\"headerlink\" title=\"HMM\"></a>HMM</h1><p>下图是《统计学习方法》中的描述：<br><img src=\"/uploads/img/20160714/hmm.png\" alt=\"隐马尔科夫模型\"><br>HMM模型将状态序列看作马尔可夫链，一阶马尔可夫链式针对相邻状态的关系进行建模，其中每个状态对应一个概率函数。HMM是一种<strong>生成模型</strong>（Generative Model），定义了联合概率分布 ，其中$x$和$y$分别表示观测序列和状态序列的随机变量。</p>\n<p>如果需要一些浅显简单的例子来理解HMM，下面的一个知乎问题和一篇博客可能有所帮助：</p>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/20962240\">如何用简单易懂的例子解释隐马尔可夫模型？</a></li>\n<li><a href=\"http://blog.csdn.net/likelet/article/details/7056068\">隐马尔可夫模型（HMM）攻略</a></li>\n</ul>\n<h1 id=\"Maximum-Entropy-Model\"><a href=\"#Maximum-Entropy-Model\" class=\"headerlink\" title=\"Maximum Entropy Model\"></a>Maximum Entropy Model</h1><p>首先贴一下关于最大熵模型的定义：<br><img src=\"/uploads/img/20160714/me.png\" alt=\"最大熵模型\"><br>最大熵模型的基本思想就是不要把所有鸡蛋放到一个篮子里。式（6.12）中的$f_i$是<strong>特征函数</strong>，代表各个约束条件。最大熵模型就是在符合所有约束条件下作出<strong>最不偏倚</strong>的假设，求得可使熵最大化的概率分布。熵最大，表示该系统内各随机事件(变量)发生的概率是近似均匀的，等可能性的。</p>\n<p>最大熵模型可以使用任意的复杂相关特征（即特征函数），在性能上最大熵分类器超过了Bayes分类器。但是，作为一种分类器模型，这两种方法有一个共同的缺点：每个词都是单独进行分类的，标记状态之间的关系无法得到充分利用，具有马尔可夫链的HMM模型可以建立标记之间的马尔可夫关联性，这是最大熵模型所没有的。</p>\n<p>最大熵模型的<strong>优点</strong>：首先，最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型;其次，最大熵统计模型可以灵活地设置约束条件，通过约束条件的多少可以调节模型对未知数据的适应度和对已知数据的拟合程度;再次，它还能自然地解决了统计模型中参数平滑的问题。</p>\n<p>最大熵模型的<strong>不足</strong>：首先，最大熵统计模型中二值化特征只是记录特征的出现是否，而文本分类需要知道特征的强度，因此，它在分类方法中不是最优的;其次，由于算法收敛的速度较慢，所以导致最大熵统计模型它的计算代价较大，时空开销大;再次，数据稀疏问题比较严重。</p>\n<h1 id=\"MEMM\"><a href=\"#MEMM\" class=\"headerlink\" title=\"MEMM\"></a>MEMM</h1><p>最大熵马尔科夫模型把HMM模型和Maximum Entropy模型的优点集合成一种<strong>生成模型</strong>（Generative Model），这个模型允许状态转移概率依赖于序列中彼此之间非独立的特征上，从而将上下文信息引入到模型的学习和识别过程中，提高了识别的精确度，召回率也大大的提高，有实验证明，这个新的模型在序列标注任务上表现的比HMM和无状态的最大熵模型要好得多。<br><img src=\"/uploads/img/20160714/memm.png\" alt=\"最大熵马尔科夫模型\"><br>可以注意到MEMM在每个节点对所有可能的状态$y$求和然后用做局部归一化的分母。所以MEMM中节点状态转移的概率都是归一化的概率。</p>\n<p>HMM模型中存在两个假设：一是输出观察值之间严格独立，二是状态的转移过程中当前状态只与前一状态有关(一阶马尔可夫模型)。但MEMM模型克服了观察值之间严格独立产生的问题，但是由于状态之间的假设理论，使得该模型仍然存在<strong>标注偏置问题</strong>（Label Bias Problem）。</p>\n<p>关于标注偏置问题，网上最多的是下面这个例子解释：<br><img src=\"/uploads/img/20160714/label-bias-1.png\" alt=\"\"><br>路径1-1-1-1的概率：0.4*0.45*0.5=0.09<br>路径2-2-2-2的概率：0.018<br>路径1-2-1-2的概率：0.06<br>路径1-1-2-2的概率：0.066<br>由此可得最优路径为：1-1-1-1<br><img src=\"/uploads/img/20160714/label-bias-2.png\" alt=\"\"><br>而实际上，在上图中，状态1偏向于转移到状态2，而状态2总倾向于停留在状态2，这就是所谓的标注偏置问题，由于分支数不同，概率的分布不均衡，导致状态的转移存在不公平的情况。<br>例子的出处参见<a href=\"http://blog.csdn.net/lskyne/article/details/8669301\">标注偏置问题(Label Bias Problem)和HMM、MEMM、CRF模型比较</a></p>\n<h1 id=\"CRF\"><a href=\"#CRF\" class=\"headerlink\" title=\"CRF\"></a>CRF</h1><p><img src=\"/uploads/img/20160714/crf-1.png\" alt=\"线性链条件随机场模型\"><br>这是书上关于条件随机场的简化形式。本文所提的CRF都不是广义上最大熵准则建模条件概率的条件随机场模型，而是约束在线性链上的特殊的条件随机场，称为线性链条件随机场（linear chain CRF）。CRF属于<strong>判别模型</strong>（Discrimitive Model）。<br><img src=\"/uploads/img/20160714/crf-2.png\" alt=\"线性链条件随机场模型图示\"><br>上式中也同样有$f_i$<strong>特征函数</strong>。之前我对模型中的特征函数一直不太理解。大家可以参考<a href=\"http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%954\">中文分词入门之字标注法4</a>这篇文章。文章主要介绍借用条件随机场工具“<a href=\"http://tenet.dl.sourceforge.net/project/crfpp/crfpp-win32/0.54/CRF%2B%2B-0.54.zip\">CRF++: Yet Another CRF toolkit</a>”来完成字标注中文分词的全过程。其中提及了特征模板文件，它的特征提取可能包含了前后多个节点的观测序列。顺便推荐一下这个非常厉害的群体博客<a href=\"http://www.52nlp.cn/\">52nlp</a>。<br>《数学之美》里“徐志摩喜欢林徽因”的例子也可供参考。</p>\n<p>CRF模型的<strong>优点</strong>：首先，CRF具有很强的推理能力，并且能够使用复杂、有重叠性和非独立的特征进行训练和推理，能够充分地利用上下文信息作为特征，还可以任意地添加其他外部特征，使得模型能够获取的信息非常丰富。其次，CRF的性能更好，CRF对特征的融合能力比较强，识别效果好于MEMM。</p>\n<p>CRF模型的<strong>不足</strong>：使用CRF方法的过程中，特征的选择和优化是影响结果的关键因素，特征选择问题的好与坏，直接决定了系统性能的高低。而且，CRF训练模型的时间较长，且获得的模型很大，在一般的PC机上无法运行。</p>\n<p>更多一些详细的CRF解释可以参考知乎的相关问题<a href=\"https://www.zhihu.com/question/35866596\">如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？</a></p>\n<h1 id=\"MEMM与CRF区别\"><a href=\"#MEMM与CRF区别\" class=\"headerlink\" title=\"MEMM与CRF区别\"></a>MEMM与CRF区别</h1><p>上面的公式都是别人贴图里的，下面的公式是我走心地敲出来的，方便看出两者的差异。</p>\n<p>MEMM的公式表示如下：<br>$$<br>\\begin{eqnarray*}<br>p(y_1, \\ldots, y_T | x_1, \\ldots, x_T) &amp;=&amp; \\prod_{i=1}^T p(y_i | x_1, \\ldots, x_T, y_{i-1}) \\\\<br>p(y_i | x_1, \\ldots, x_T, y_{i-1}) &amp;=&amp;<br>\\frac{exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y_i)}<br>{\\sum\\limits_y exp(\\sum\\limits_{k=1}^K w_{k}f_k(x_1, \\ldots, x_T, y_{i-1}, y)}<br>\\end{eqnarray*}<br>$$<br>线性链CRF的公式表示如下：<br>$$<br>\\begin{eqnarray*}<br>p(y|x) &amp;=&amp; \\frac{p(y, x)}{\\sum\\limits_Y p(y, x)}<br>\\\\<br>&amp;=&amp; \\frac{\\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x))}<br>{\\sum\\limits_Y \\prod\\limits_{t=1}^T exp(\\sum\\limits_{k=1}^K w_k f_k(y_t, y_{t-1}, x)) }<br>\\end{eqnarray*}<br>$$<br>不同点：</p>\n<ul>\n<li>首先，CRF是<strong>判别模型</strong>，而MEMM我个人理解是<strong>生成模型</strong>。MEMM是在HMM基础上的优化，它保留了“状态的转移过程中当前状态只与前一状态有关”这一个独立性假设，状态与状态之间的转移仍是遵循一个<strong>不大于1</strong>的、只在同一结点作归一化的局部归一化概率，与HMM的思想相近。</li>\n<li>MEMM和CRF的<strong>归一化位置</strong>不同。从上面的公式可以看出，MEMM是在given前一状态$y_{i-1}$的情况下，对下一个节点所有可能的$y_i$作局部的归一化，利用最大熵模型，从观测序列$x$和前一状态$y_{i-1}$中的特征学习到$y_i$的分布。而CRF是对$Y$中所有可能的状态序列作全局的归一化，假设每个节点有$L$中状态，序列中有$T$个节点，那么所有可能的状态序列数为$L^T$，这导致在模型学习时会较为复杂。</li>\n<li>MEMM在用<strong>viterbi算法</strong>求解最优路径时，每次乘上的是个归一化概率，而CRF乘上的是一个自然指数，没有经过归一化。当遇到某些不公平的情况：某条路径自然指数本身很小，但归一化后变为一个很大的概率比如0.9，而同时即使别的路径自然指数很大，但它们竞争也激烈，归一化后的概率反而不大，这样前一条路径就会被选中，导致了之前提过的标记偏置问题，而CRF可以避免这一问题。</li>\n</ul>\n<p>关于MEMM和CRF两者的区别，推荐可以参考下面的一个知乎问题和一篇博客：</p>\n<ul>\n<li><a href=\"https://www.zhihu.com/question/30869789\">MEMM和CRF有什么不同？</a></li>\n<li><a href=\"http://blog.sina.com.cn/s/blog_8af106960102v0v1.html\">统计模型之间的比较，HMM，最大熵模型，CRF条件随机场 </a></li>\n</ul>\n<h1 id=\"写在最后\"><a href=\"#写在最后\" class=\"headerlink\" title=\"写在最后\"></a>写在最后</h1><p>关于用做封面的那张图，是对相关模型一个非常抽象、宏观的转换图，感觉非常精髓，出处为<a href=\"http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf\">An introduction to conditional random fields</a>。</p>\n<p>以上均为本小白个人理解，如有任何不当或者错误，欢迎指正。</p>\n"},{"title":"基于Neo4j的知乎关系爬虫","date":"2016-06-29T03:15:56.000Z","comments":1,"photos":["/uploads/img/20160629/cover.jpg"],"_content":"前两天做了一个爬取知乎用户**follow**关系的爬虫。做这个爬虫是受一个知乎专栏的启发[Web Crawler with Python - 09.怎样通过爬虫找出我和轮子哥、四万姐之间的最短关系](https://zhuanlan.zhihu.com/p/20546546)，我有部分代码参考了xlzd。由于当时也想了解一下NoSQL里Graph Database，于是花了几天时间做了一个简单的爬虫，感觉收获不少。封面图片可以理解成是一个**六度分隔理论**的直观展现，也是我在做爬虫时的意外验证。\n# 环境安装\n\n首先交代一下爬虫所用到的数据库和环境：\n## MongoDB\nMongoDB一种基于分布式文件存储的数据库，属于NoSQL里的文档型数据库。它的性能较高，面向集合存储，爬虫所抓取的用户信息都存储在其中。\n在python里使用MongoDB，只需要在本机下载安装MongoDB服务，在python的环境里安装pymongo依赖，`pip install pymongo`就可以了。如果嫌MongoDB的命令行操作不方便，可以装一个MongoDB的可视化工具[Robomongo](https://robomongo.org/)。\n\n## Neo4j\nNeo4j是一个高性能的,NoSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。\n关于Neo4j的安装，可以参考这篇博客[Neo4j介绍与使用](http://blog.csdn.net/dyllove98/article/details/8635965)。Win7环境下，官网[下载](https://neo4j.com/download/)可以一键安装Neo4j。\n\nNeo4j使用类似SQL的查询语言**Cypher**，关于Cypher的使用和简单demo，可以参考[Cypher查询语言--Neo4j中的SQL](http://www.uml.org.cn/sjjm/201203063.asp)。当然，为了减少学习Cypher的时间成本，我在python环境中安装了**py2neo**，`pip install py2neo`。\n\npy2neo的handbook见[The Py2neo v3 Handbook](http://py2neo.org/v3/)。我对py2neo依赖库的理解：py2neo是一个Neo4j的客户端，其中对Neo4j的操作进行了封装。调用py2neo的一个函数，它会自动转化为Cypher语言并以HTTP API向Neo4j服务端口提交一个事务。当然它也支持直接提交Cypher语句到Neo4j执行，有些复杂的数据操作比如寻找两点之间最短路径，py2neo没有提供直接的函数调用，需要我们自己编写Cypher。\n\n## python依赖\n* requests\nrequests是一个非常好用的网络依赖包，API文档见[Requests: HTTP for Humans](http://www.python-requests.org/en/master/)。文档网站的名字“HTTP for Humans”，算是程序员的一种幽默吧。\n* BeautifulSoup\nBeautifulSoup依赖库是一个非常实用的HTML解析器，不需要程序员再焦头烂额地写RegEx。虽然开发友好了，但解析时有时会出一些不可思议的bug。API文档见[Beautiful Soup 4.2.0 文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)。\n\n# 爬虫概要\n## 目的\n我爬虫的目的非常简单，和开头的那篇专栏一样：知乎大V---轮子哥（**vczh**）需要通过多少人才能认识并关注我？这里的认识是指单方面的知道，即成为我的follower（不需要为followee，虽然这是肯定的），知道这世界原来还有个知乎用户“**三天三夜**”。\n## 开发思路\n爬虫从我自己的知乎出发，读取我的follower列表，对我的每个follower重复搜索操作，直到搜索到的follower list里有vczh。这个遍历是**BFS**的。当然，为了防止在广度优先搜索时，层与层之间节点数量扩张过快，我限制只搜索follower num**不超过100**的不活跃的小用户，当然我提前调查了轮子哥也有follow一些这种小用户。除了为了防止扩张过快导致的存储空间过大，这样做也给验证六度分隔理论提了更为苛刻的条件，毕竟轮子哥通过其他大V能follow到我的概率是远大于通过小用户的。\n## 代码相关\n整个爬虫的代码我push到Github上，附上[链接](https://github.com/tripleday/zhihu_link)。\n贴上几个想到的小细节：\n* 这个爬虫需要自己的知乎cookie才能爬取。建议使用chrome，安装**EditThisCookie**插件，将知乎的cookie复制粘贴到zhihu_cookie.json文件。\n* 知乎用户的唯一性不是靠用户名，而是html里内嵌隐藏的**data-id**，在ajax获取数据是发送的表单数据里也需要这个值。所以Neo4j中使用此值可以唯一标识用户。\n* BeautifulSoup的官方文档里的一张解析器对比表格\n\n![BeautifulSoup解析器对比](/uploads/img/20160629/bs.png)\n实际使用中，在解析`https://www.zhihu.com/people/hong-ming-da`这条链接时，lxml解析一直都会出错，换成html.parser后解析成功。所以html.parser虽然解析速度慢，但容错性更好一点。\n* 代码中有关知乎爬虫的代码，我是在[egrcc/zhihu-python](https://github.com/egrcc/zhihu-python)的基础上改动的，非常感谢原作者的分享。\n* 其他的细节想到后再补充。\n\n# 爬取结果\n\n爬虫程序在爬了23928个用户才停下来，即找到了轮子哥。这是爬完的部分用户图：\n![部分用户关系图](/uploads/img/20160629/whole.png)\n\n在命令行执行Cypher语句：`MATCH (a {_id : '0970f947b898ecc0ec035f9126dd4e08'}), (b {_id : 'bd648b6ef0f14880a522e09ce2752465'}), p = allShortestPaths( (a)-[*..200]->(b) ) RETURN p`可以得到轮子哥到我的最短路径：\n![最短路径图](/uploads/img/20160629/shortestpath.png)\n\n可以发现：轮子哥到我，中间正好经过了6个人。这条路的生成条件是较为严格的。不仅是因为我只选择的小用户进行爬取，而且要知道我的follower目前是只有一个的，轮子哥要连接到我只能通过他。虽然实验得到的 **6** 可能和六度分隔理论恰巧吻合，但鉴于路径选择的苛刻条件，六度的6也许并不只是一种猜想。\n","source":"_posts/zhihu-link.md","raw":"title: 基于Neo4j的知乎关系爬虫\ndate: 2016-06-29 11:15:56\ncomments: true\ntags: \n - zhihu\n - Neo4j\n - python\ncategories: Crawler\nphotos: \n - /uploads/img/20160629/cover.jpg\n---\n前两天做了一个爬取知乎用户**follow**关系的爬虫。做这个爬虫是受一个知乎专栏的启发[Web Crawler with Python - 09.怎样通过爬虫找出我和轮子哥、四万姐之间的最短关系](https://zhuanlan.zhihu.com/p/20546546)，我有部分代码参考了xlzd。由于当时也想了解一下NoSQL里Graph Database，于是花了几天时间做了一个简单的爬虫，感觉收获不少。封面图片可以理解成是一个**六度分隔理论**的直观展现，也是我在做爬虫时的意外验证。\n# 环境安装\n\n首先交代一下爬虫所用到的数据库和环境：\n## MongoDB\nMongoDB一种基于分布式文件存储的数据库，属于NoSQL里的文档型数据库。它的性能较高，面向集合存储，爬虫所抓取的用户信息都存储在其中。\n在python里使用MongoDB，只需要在本机下载安装MongoDB服务，在python的环境里安装pymongo依赖，`pip install pymongo`就可以了。如果嫌MongoDB的命令行操作不方便，可以装一个MongoDB的可视化工具[Robomongo](https://robomongo.org/)。\n\n## Neo4j\nNeo4j是一个高性能的,NoSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。\n关于Neo4j的安装，可以参考这篇博客[Neo4j介绍与使用](http://blog.csdn.net/dyllove98/article/details/8635965)。Win7环境下，官网[下载](https://neo4j.com/download/)可以一键安装Neo4j。\n\nNeo4j使用类似SQL的查询语言**Cypher**，关于Cypher的使用和简单demo，可以参考[Cypher查询语言--Neo4j中的SQL](http://www.uml.org.cn/sjjm/201203063.asp)。当然，为了减少学习Cypher的时间成本，我在python环境中安装了**py2neo**，`pip install py2neo`。\n\npy2neo的handbook见[The Py2neo v3 Handbook](http://py2neo.org/v3/)。我对py2neo依赖库的理解：py2neo是一个Neo4j的客户端，其中对Neo4j的操作进行了封装。调用py2neo的一个函数，它会自动转化为Cypher语言并以HTTP API向Neo4j服务端口提交一个事务。当然它也支持直接提交Cypher语句到Neo4j执行，有些复杂的数据操作比如寻找两点之间最短路径，py2neo没有提供直接的函数调用，需要我们自己编写Cypher。\n\n## python依赖\n* requests\nrequests是一个非常好用的网络依赖包，API文档见[Requests: HTTP for Humans](http://www.python-requests.org/en/master/)。文档网站的名字“HTTP for Humans”，算是程序员的一种幽默吧。\n* BeautifulSoup\nBeautifulSoup依赖库是一个非常实用的HTML解析器，不需要程序员再焦头烂额地写RegEx。虽然开发友好了，但解析时有时会出一些不可思议的bug。API文档见[Beautiful Soup 4.2.0 文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)。\n\n# 爬虫概要\n## 目的\n我爬虫的目的非常简单，和开头的那篇专栏一样：知乎大V---轮子哥（**vczh**）需要通过多少人才能认识并关注我？这里的认识是指单方面的知道，即成为我的follower（不需要为followee，虽然这是肯定的），知道这世界原来还有个知乎用户“**三天三夜**”。\n## 开发思路\n爬虫从我自己的知乎出发，读取我的follower列表，对我的每个follower重复搜索操作，直到搜索到的follower list里有vczh。这个遍历是**BFS**的。当然，为了防止在广度优先搜索时，层与层之间节点数量扩张过快，我限制只搜索follower num**不超过100**的不活跃的小用户，当然我提前调查了轮子哥也有follow一些这种小用户。除了为了防止扩张过快导致的存储空间过大，这样做也给验证六度分隔理论提了更为苛刻的条件，毕竟轮子哥通过其他大V能follow到我的概率是远大于通过小用户的。\n## 代码相关\n整个爬虫的代码我push到Github上，附上[链接](https://github.com/tripleday/zhihu_link)。\n贴上几个想到的小细节：\n* 这个爬虫需要自己的知乎cookie才能爬取。建议使用chrome，安装**EditThisCookie**插件，将知乎的cookie复制粘贴到zhihu_cookie.json文件。\n* 知乎用户的唯一性不是靠用户名，而是html里内嵌隐藏的**data-id**，在ajax获取数据是发送的表单数据里也需要这个值。所以Neo4j中使用此值可以唯一标识用户。\n* BeautifulSoup的官方文档里的一张解析器对比表格\n\n![BeautifulSoup解析器对比](/uploads/img/20160629/bs.png)\n实际使用中，在解析`https://www.zhihu.com/people/hong-ming-da`这条链接时，lxml解析一直都会出错，换成html.parser后解析成功。所以html.parser虽然解析速度慢，但容错性更好一点。\n* 代码中有关知乎爬虫的代码，我是在[egrcc/zhihu-python](https://github.com/egrcc/zhihu-python)的基础上改动的，非常感谢原作者的分享。\n* 其他的细节想到后再补充。\n\n# 爬取结果\n\n爬虫程序在爬了23928个用户才停下来，即找到了轮子哥。这是爬完的部分用户图：\n![部分用户关系图](/uploads/img/20160629/whole.png)\n\n在命令行执行Cypher语句：`MATCH (a {_id : '0970f947b898ecc0ec035f9126dd4e08'}), (b {_id : 'bd648b6ef0f14880a522e09ce2752465'}), p = allShortestPaths( (a)-[*..200]->(b) ) RETURN p`可以得到轮子哥到我的最短路径：\n![最短路径图](/uploads/img/20160629/shortestpath.png)\n\n可以发现：轮子哥到我，中间正好经过了6个人。这条路的生成条件是较为严格的。不仅是因为我只选择的小用户进行爬取，而且要知道我的follower目前是只有一个的，轮子哥要连接到我只能通过他。虽然实验得到的 **6** 可能和六度分隔理论恰巧吻合，但鉴于路径选择的苛刻条件，六度的6也许并不只是一种猜想。\n","slug":"zhihu-link","published":1,"updated":"2016-07-20T13:49:47.806Z","layout":"post","link":"","_id":"ciquyzdgq0005ewc50rqy1m9e","content":"<p>前两天做了一个爬取知乎用户<strong>follow</strong>关系的爬虫。做这个爬虫是受一个知乎专栏的启发<a href=\"https://zhuanlan.zhihu.com/p/20546546\" target=\"_blank\" rel=\"external\">Web Crawler with Python - 09.怎样通过爬虫找出我和轮子哥、四万姐之间的最短关系</a>，我有部分代码参考了xlzd。由于当时也想了解一下NoSQL里Graph Database，于是花了几天时间做了一个简单的爬虫，感觉收获不少。封面图片可以理解成是一个<strong>六度分隔理论</strong>的直观展现，也是我在做爬虫时的意外验证。</p>\n<h1 id=\"环境安装\"><a href=\"#环境安装\" class=\"headerlink\" title=\"环境安装\"></a>环境安装</h1><p>首先交代一下爬虫所用到的数据库和环境：</p>\n<h2 id=\"MongoDB\"><a href=\"#MongoDB\" class=\"headerlink\" title=\"MongoDB\"></a>MongoDB</h2><p>MongoDB一种基于分布式文件存储的数据库，属于NoSQL里的文档型数据库。它的性能较高，面向集合存储，爬虫所抓取的用户信息都存储在其中。<br>在python里使用MongoDB，只需要在本机下载安装MongoDB服务，在python的环境里安装pymongo依赖，<code>pip install pymongo</code>就可以了。如果嫌MongoDB的命令行操作不方便，可以装一个MongoDB的可视化工具<a href=\"https://robomongo.org/\" target=\"_blank\" rel=\"external\">Robomongo</a>。</p>\n<h2 id=\"Neo4j\"><a href=\"#Neo4j\" class=\"headerlink\" title=\"Neo4j\"></a>Neo4j</h2><p>Neo4j是一个高性能的,NoSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。<br>关于Neo4j的安装，可以参考这篇博客<a href=\"http://blog.csdn.net/dyllove98/article/details/8635965\" target=\"_blank\" rel=\"external\">Neo4j介绍与使用</a>。Win7环境下，官网<a href=\"https://neo4j.com/download/\" target=\"_blank\" rel=\"external\">下载</a>可以一键安装Neo4j。</p>\n<p>Neo4j使用类似SQL的查询语言<strong>Cypher</strong>，关于Cypher的使用和简单demo，可以参考<a href=\"http://www.uml.org.cn/sjjm/201203063.asp\" target=\"_blank\" rel=\"external\">Cypher查询语言–Neo4j中的SQL</a>。当然，为了减少学习Cypher的时间成本，我在python环境中安装了<strong>py2neo</strong>，<code>pip install py2neo</code>。</p>\n<p>py2neo的handbook见<a href=\"http://py2neo.org/v3/\" target=\"_blank\" rel=\"external\">The Py2neo v3 Handbook</a>。我对py2neo依赖库的理解：py2neo是一个Neo4j的客户端，其中对Neo4j的操作进行了封装。调用py2neo的一个函数，它会自动转化为Cypher语言并以HTTP API向Neo4j服务端口提交一个事务。当然它也支持直接提交Cypher语句到Neo4j执行，有些复杂的数据操作比如寻找两点之间最短路径，py2neo没有提供直接的函数调用，需要我们自己编写Cypher。</p>\n<h2 id=\"python依赖\"><a href=\"#python依赖\" class=\"headerlink\" title=\"python依赖\"></a>python依赖</h2><ul>\n<li>requests<br>requests是一个非常好用的网络依赖包，API文档见<a href=\"http://www.python-requests.org/en/master/\" target=\"_blank\" rel=\"external\">Requests: HTTP for Humans</a>。文档网站的名字“HTTP for Humans”，算是程序员的一种幽默吧。</li>\n<li>BeautifulSoup<br>BeautifulSoup依赖库是一个非常实用的HTML解析器，不需要程序员再焦头烂额地写RegEx。虽然开发友好了，但解析时有时会出一些不可思议的bug。API文档见<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/\" target=\"_blank\" rel=\"external\">Beautiful Soup 4.2.0 文档</a>。</li>\n</ul>\n<h1 id=\"爬虫概要\"><a href=\"#爬虫概要\" class=\"headerlink\" title=\"爬虫概要\"></a>爬虫概要</h1><h2 id=\"目的\"><a href=\"#目的\" class=\"headerlink\" title=\"目的\"></a>目的</h2><p>我爬虫的目的非常简单，和开头的那篇专栏一样：知乎大V—轮子哥（<strong>vczh</strong>）需要通过多少人才能认识并关注我？这里的认识是指单方面的知道，即成为我的follower（不需要为followee，虽然这是肯定的），知道这世界原来还有个知乎用户“<strong>三天三夜</strong>”。</p>\n<h2 id=\"开发思路\"><a href=\"#开发思路\" class=\"headerlink\" title=\"开发思路\"></a>开发思路</h2><p>爬虫从我自己的知乎出发，读取我的follower列表，对我的每个follower重复搜索操作，直到搜索到的follower list里有vczh。这个遍历是<strong>BFS</strong>的。当然，为了防止在广度优先搜索时，层与层之间节点数量扩张过快，我限制只搜索follower num<strong>不超过100</strong>的不活跃的小用户，当然我提前调查了轮子哥也有follow一些这种小用户。除了为了防止扩张过快导致的存储空间过大，这样做也给验证六度分隔理论提了更为苛刻的条件，毕竟轮子哥通过其他大V能follow到我的概率是远大于通过小用户的。</p>\n<h2 id=\"代码相关\"><a href=\"#代码相关\" class=\"headerlink\" title=\"代码相关\"></a>代码相关</h2><p>整个爬虫的代码我push到Github上，附上<a href=\"https://github.com/tripleday/zhihu_link\" target=\"_blank\" rel=\"external\">链接</a>。<br>贴上几个想到的小细节：</p>\n<ul>\n<li>这个爬虫需要自己的知乎cookie才能爬取。建议使用chrome，安装<strong>EditThisCookie</strong>插件，将知乎的cookie复制粘贴到zhihu_cookie.json文件。</li>\n<li>知乎用户的唯一性不是靠用户名，而是html里内嵌隐藏的<strong>data-id</strong>，在ajax获取数据是发送的表单数据里也需要这个值。所以Neo4j中使用此值可以唯一标识用户。</li>\n<li>BeautifulSoup的官方文档里的一张解析器对比表格</li>\n</ul>\n<p><img src=\"/uploads/img/20160629/bs.png\" alt=\"BeautifulSoup解析器对比\"><br>实际使用中，在解析<code>https://www.zhihu.com/people/hong-ming-da</code>这条链接时，lxml解析一直都会出错，换成html.parser后解析成功。所以html.parser虽然解析速度慢，但容错性更好一点。</p>\n<ul>\n<li>代码中有关知乎爬虫的代码，我是在<a href=\"https://github.com/egrcc/zhihu-python\" target=\"_blank\" rel=\"external\">egrcc/zhihu-python</a>的基础上改动的，非常感谢原作者的分享。</li>\n<li>其他的细节想到后再补充。</li>\n</ul>\n<h1 id=\"爬取结果\"><a href=\"#爬取结果\" class=\"headerlink\" title=\"爬取结果\"></a>爬取结果</h1><p>爬虫程序在爬了23928个用户才停下来，即找到了轮子哥。这是爬完的部分用户图：<br><img src=\"/uploads/img/20160629/whole.png\" alt=\"部分用户关系图\"></p>\n<p>在命令行执行Cypher语句：<code>MATCH (a {_id : &#39;0970f947b898ecc0ec035f9126dd4e08&#39;}), (b {_id : &#39;bd648b6ef0f14880a522e09ce2752465&#39;}), p = allShortestPaths( (a)-[*..200]-&gt;(b) ) RETURN p</code>可以得到轮子哥到我的最短路径：<br><img src=\"/uploads/img/20160629/shortestpath.png\" alt=\"最短路径图\"></p>\n<p>可以发现：轮子哥到我，中间正好经过了6个人。这条路的生成条件是较为严格的。不仅是因为我只选择的小用户进行爬取，而且要知道我的follower目前是只有一个的，轮子哥要连接到我只能通过他。虽然实验得到的 <strong>6</strong> 可能和六度分隔理论恰巧吻合，但鉴于路径选择的苛刻条件，六度的6也许并不只是一种猜想。</p>\n","excerpt":"","more":"<p>前两天做了一个爬取知乎用户<strong>follow</strong>关系的爬虫。做这个爬虫是受一个知乎专栏的启发<a href=\"https://zhuanlan.zhihu.com/p/20546546\">Web Crawler with Python - 09.怎样通过爬虫找出我和轮子哥、四万姐之间的最短关系</a>，我有部分代码参考了xlzd。由于当时也想了解一下NoSQL里Graph Database，于是花了几天时间做了一个简单的爬虫，感觉收获不少。封面图片可以理解成是一个<strong>六度分隔理论</strong>的直观展现，也是我在做爬虫时的意外验证。</p>\n<h1 id=\"环境安装\"><a href=\"#环境安装\" class=\"headerlink\" title=\"环境安装\"></a>环境安装</h1><p>首先交代一下爬虫所用到的数据库和环境：</p>\n<h2 id=\"MongoDB\"><a href=\"#MongoDB\" class=\"headerlink\" title=\"MongoDB\"></a>MongoDB</h2><p>MongoDB一种基于分布式文件存储的数据库，属于NoSQL里的文档型数据库。它的性能较高，面向集合存储，爬虫所抓取的用户信息都存储在其中。<br>在python里使用MongoDB，只需要在本机下载安装MongoDB服务，在python的环境里安装pymongo依赖，<code>pip install pymongo</code>就可以了。如果嫌MongoDB的命令行操作不方便，可以装一个MongoDB的可视化工具<a href=\"https://robomongo.org/\">Robomongo</a>。</p>\n<h2 id=\"Neo4j\"><a href=\"#Neo4j\" class=\"headerlink\" title=\"Neo4j\"></a>Neo4j</h2><p>Neo4j是一个高性能的,NoSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。<br>关于Neo4j的安装，可以参考这篇博客<a href=\"http://blog.csdn.net/dyllove98/article/details/8635965\">Neo4j介绍与使用</a>。Win7环境下，官网<a href=\"https://neo4j.com/download/\">下载</a>可以一键安装Neo4j。</p>\n<p>Neo4j使用类似SQL的查询语言<strong>Cypher</strong>，关于Cypher的使用和简单demo，可以参考<a href=\"http://www.uml.org.cn/sjjm/201203063.asp\">Cypher查询语言–Neo4j中的SQL</a>。当然，为了减少学习Cypher的时间成本，我在python环境中安装了<strong>py2neo</strong>，<code>pip install py2neo</code>。</p>\n<p>py2neo的handbook见<a href=\"http://py2neo.org/v3/\">The Py2neo v3 Handbook</a>。我对py2neo依赖库的理解：py2neo是一个Neo4j的客户端，其中对Neo4j的操作进行了封装。调用py2neo的一个函数，它会自动转化为Cypher语言并以HTTP API向Neo4j服务端口提交一个事务。当然它也支持直接提交Cypher语句到Neo4j执行，有些复杂的数据操作比如寻找两点之间最短路径，py2neo没有提供直接的函数调用，需要我们自己编写Cypher。</p>\n<h2 id=\"python依赖\"><a href=\"#python依赖\" class=\"headerlink\" title=\"python依赖\"></a>python依赖</h2><ul>\n<li>requests<br>requests是一个非常好用的网络依赖包，API文档见<a href=\"http://www.python-requests.org/en/master/\">Requests: HTTP for Humans</a>。文档网站的名字“HTTP for Humans”，算是程序员的一种幽默吧。</li>\n<li>BeautifulSoup<br>BeautifulSoup依赖库是一个非常实用的HTML解析器，不需要程序员再焦头烂额地写RegEx。虽然开发友好了，但解析时有时会出一些不可思议的bug。API文档见<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/\">Beautiful Soup 4.2.0 文档</a>。</li>\n</ul>\n<h1 id=\"爬虫概要\"><a href=\"#爬虫概要\" class=\"headerlink\" title=\"爬虫概要\"></a>爬虫概要</h1><h2 id=\"目的\"><a href=\"#目的\" class=\"headerlink\" title=\"目的\"></a>目的</h2><p>我爬虫的目的非常简单，和开头的那篇专栏一样：知乎大V—轮子哥（<strong>vczh</strong>）需要通过多少人才能认识并关注我？这里的认识是指单方面的知道，即成为我的follower（不需要为followee，虽然这是肯定的），知道这世界原来还有个知乎用户“<strong>三天三夜</strong>”。</p>\n<h2 id=\"开发思路\"><a href=\"#开发思路\" class=\"headerlink\" title=\"开发思路\"></a>开发思路</h2><p>爬虫从我自己的知乎出发，读取我的follower列表，对我的每个follower重复搜索操作，直到搜索到的follower list里有vczh。这个遍历是<strong>BFS</strong>的。当然，为了防止在广度优先搜索时，层与层之间节点数量扩张过快，我限制只搜索follower num<strong>不超过100</strong>的不活跃的小用户，当然我提前调查了轮子哥也有follow一些这种小用户。除了为了防止扩张过快导致的存储空间过大，这样做也给验证六度分隔理论提了更为苛刻的条件，毕竟轮子哥通过其他大V能follow到我的概率是远大于通过小用户的。</p>\n<h2 id=\"代码相关\"><a href=\"#代码相关\" class=\"headerlink\" title=\"代码相关\"></a>代码相关</h2><p>整个爬虫的代码我push到Github上，附上<a href=\"https://github.com/tripleday/zhihu_link\">链接</a>。<br>贴上几个想到的小细节：</p>\n<ul>\n<li>这个爬虫需要自己的知乎cookie才能爬取。建议使用chrome，安装<strong>EditThisCookie</strong>插件，将知乎的cookie复制粘贴到zhihu_cookie.json文件。</li>\n<li>知乎用户的唯一性不是靠用户名，而是html里内嵌隐藏的<strong>data-id</strong>，在ajax获取数据是发送的表单数据里也需要这个值。所以Neo4j中使用此值可以唯一标识用户。</li>\n<li>BeautifulSoup的官方文档里的一张解析器对比表格</li>\n</ul>\n<p><img src=\"/uploads/img/20160629/bs.png\" alt=\"BeautifulSoup解析器对比\"><br>实际使用中，在解析<code>https://www.zhihu.com/people/hong-ming-da</code>这条链接时，lxml解析一直都会出错，换成html.parser后解析成功。所以html.parser虽然解析速度慢，但容错性更好一点。</p>\n<ul>\n<li>代码中有关知乎爬虫的代码，我是在<a href=\"https://github.com/egrcc/zhihu-python\">egrcc/zhihu-python</a>的基础上改动的，非常感谢原作者的分享。</li>\n<li>其他的细节想到后再补充。</li>\n</ul>\n<h1 id=\"爬取结果\"><a href=\"#爬取结果\" class=\"headerlink\" title=\"爬取结果\"></a>爬取结果</h1><p>爬虫程序在爬了23928个用户才停下来，即找到了轮子哥。这是爬完的部分用户图：<br><img src=\"/uploads/img/20160629/whole.png\" alt=\"部分用户关系图\"></p>\n<p>在命令行执行Cypher语句：<code>MATCH (a {_id : &#39;0970f947b898ecc0ec035f9126dd4e08&#39;}), (b {_id : &#39;bd648b6ef0f14880a522e09ce2752465&#39;}), p = allShortestPaths( (a)-[*..200]-&gt;(b) ) RETURN p</code>可以得到轮子哥到我的最短路径：<br><img src=\"/uploads/img/20160629/shortestpath.png\" alt=\"最短路径图\"></p>\n<p>可以发现：轮子哥到我，中间正好经过了6个人。这条路的生成条件是较为严格的。不仅是因为我只选择的小用户进行爬取，而且要知道我的follower目前是只有一个的，轮子哥要连接到我只能通过他。虽然实验得到的 <strong>6</strong> 可能和六度分隔理论恰巧吻合，但鉴于路径选择的苛刻条件，六度的6也许并不只是一种猜想。</p>\n"},{"title":"使用python将图片转化为字符画","date":"2016-07-20T13:35:43.000Z","comments":1,"photos":["/uploads/img/20160720/cover.png"],"_content":"忽然想玩这个图片转化的把戏，是因为之前在知乎上看到一个专栏里用到了下面这个图：\n![拿衣服](/uploads/img/20160720/mo.jpg)\n当然，那篇专栏没过几小时就被和谐了。我在网上貌似搜到了这个图片转emoji mosaic的网址，供大家戏耍：[Emoji Mosaic](http://ericandrewlewis.github.io/emoji-mosaic/)。\n\n做这个转emoji马赛克应该蛮复杂的，当然它的源码也很容易找到：[ericandrewlewis/emoji-mosaic](https://github.com/ericandrewlewis/emoji-mosaic)。但我纯属娱乐又不想花功夫，于是就在晚上学了学把图片转为字符图的代码玩玩。\n\n代码很简单：\n```python\n#-*- coding: utf-8 -*-\nfrom PIL import Image\n \ngrey2char = ['@','#','$','%','&','?','*','o','/','{','[','(','|','!','^','~','-','_',':',';',',','.','`',' ']\ncount = len(grey2char)\n \ndef toText(image_file):\n   image_file = image_file.convert('L')# 转灰度\n   result = ''# 储存字符串\n   for h in range(0,  image_file.size[1]):# height\n      for w in range(0, image_file.size[0]):# width\n         gray = image_file.getpixel((w,h))\n         result += grey2char[int(gray/(255/(count-1)))]\n      result += '\\r\\n'\n   return result\n \nimage_file = Image.open(\"input.jpg\")# 打开图片\nimage_file = image_file.resize((int(image_file.size[0]), int(image_file.size[1]*0.55)))# 调整图片大小\n \noutput = open('output.txt','w')\noutput.write(toText(image_file))\noutput.close()\n```\n需要注意的是要安装依赖PIL。\n原图：\n![](/uploads/img/20160720/input.jpg)\n\n字符图：\n![](/uploads/img/20160720/cover.png)\n","source":"_posts/img2txt.md","raw":"title: 使用python将图片转化为字符画\ndate: 2016-07-20 21:35:43\ncomments: true\ntags: \n - PIL\n - python\ncategories: Fun\nphotos: \n - /uploads/img/20160720/cover.png\n---\n忽然想玩这个图片转化的把戏，是因为之前在知乎上看到一个专栏里用到了下面这个图：\n![拿衣服](/uploads/img/20160720/mo.jpg)\n当然，那篇专栏没过几小时就被和谐了。我在网上貌似搜到了这个图片转emoji mosaic的网址，供大家戏耍：[Emoji Mosaic](http://ericandrewlewis.github.io/emoji-mosaic/)。\n\n做这个转emoji马赛克应该蛮复杂的，当然它的源码也很容易找到：[ericandrewlewis/emoji-mosaic](https://github.com/ericandrewlewis/emoji-mosaic)。但我纯属娱乐又不想花功夫，于是就在晚上学了学把图片转为字符图的代码玩玩。\n\n代码很简单：\n```python\n#-*- coding: utf-8 -*-\nfrom PIL import Image\n \ngrey2char = ['@','#','$','%','&','?','*','o','/','{','[','(','|','!','^','~','-','_',':',';',',','.','`',' ']\ncount = len(grey2char)\n \ndef toText(image_file):\n   image_file = image_file.convert('L')# 转灰度\n   result = ''# 储存字符串\n   for h in range(0,  image_file.size[1]):# height\n      for w in range(0, image_file.size[0]):# width\n         gray = image_file.getpixel((w,h))\n         result += grey2char[int(gray/(255/(count-1)))]\n      result += '\\r\\n'\n   return result\n \nimage_file = Image.open(\"input.jpg\")# 打开图片\nimage_file = image_file.resize((int(image_file.size[0]), int(image_file.size[1]*0.55)))# 调整图片大小\n \noutput = open('output.txt','w')\noutput.write(toText(image_file))\noutput.close()\n```\n需要注意的是要安装依赖PIL。\n原图：\n![](/uploads/img/20160720/input.jpg)\n\n字符图：\n![](/uploads/img/20160720/cover.png)\n","slug":"img2txt","published":1,"updated":"2016-07-20T14:13:36.866Z","layout":"post","link":"","_id":"ciquyzdgt0007ewc5raetbzlx","content":"<p>忽然想玩这个图片转化的把戏，是因为之前在知乎上看到一个专栏里用到了下面这个图：<br><img src=\"/uploads/img/20160720/mo.jpg\" alt=\"拿衣服\"><br>当然，那篇专栏没过几小时就被和谐了。我在网上貌似搜到了这个图片转emoji mosaic的网址，供大家戏耍：<a href=\"http://ericandrewlewis.github.io/emoji-mosaic/\" target=\"_blank\" rel=\"external\">Emoji Mosaic</a>。</p>\n<p>做这个转emoji马赛克应该蛮复杂的，当然它的源码也很容易找到：<a href=\"https://github.com/ericandrewlewis/emoji-mosaic\" target=\"_blank\" rel=\"external\">ericandrewlewis/emoji-mosaic</a>。但我纯属娱乐又不想花功夫，于是就在晚上学了学把图片转为字符图的代码玩玩。</p>\n<p>代码很简单：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#-*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"> </span><br><span class=\"line\">grey2char = [<span class=\"string\">'@'</span>,<span class=\"string\">'#'</span>,<span class=\"string\">'$'</span>,<span class=\"string\">'%'</span>,<span class=\"string\">'&amp;'</span>,<span class=\"string\">'?'</span>,<span class=\"string\">'*'</span>,<span class=\"string\">'o'</span>,<span class=\"string\">'/'</span>,<span class=\"string\">'&#123;'</span>,<span class=\"string\">'['</span>,<span class=\"string\">'('</span>,<span class=\"string\">'|'</span>,<span class=\"string\">'!'</span>,<span class=\"string\">'^'</span>,<span class=\"string\">'~'</span>,<span class=\"string\">'-'</span>,<span class=\"string\">'_'</span>,<span class=\"string\">':'</span>,<span class=\"string\">';'</span>,<span class=\"string\">','</span>,<span class=\"string\">'.'</span>,<span class=\"string\">'`'</span>,<span class=\"string\">' '</span>]</span><br><span class=\"line\">count = len(grey2char)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">toText</span><span class=\"params\">(image_file)</span>:</span></span><br><span class=\"line\">   image_file = image_file.convert(<span class=\"string\">'L'</span>)<span class=\"comment\"># 转灰度</span></span><br><span class=\"line\">   result = <span class=\"string\">''</span><span class=\"comment\"># 储存字符串</span></span><br><span class=\"line\">   <span class=\"keyword\">for</span> h <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>,  image_file.size[<span class=\"number\">1</span>]):<span class=\"comment\"># height</span></span><br><span class=\"line\">      <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, image_file.size[<span class=\"number\">0</span>]):<span class=\"comment\"># width</span></span><br><span class=\"line\">         gray = image_file.getpixel((w,h))</span><br><span class=\"line\">         result += grey2char[int(gray/(<span class=\"number\">255</span>/(count<span class=\"number\">-1</span>)))]</span><br><span class=\"line\">      result += <span class=\"string\">'\\r\\n'</span></span><br><span class=\"line\">   <span class=\"keyword\">return</span> result</span><br><span class=\"line\"> </span><br><span class=\"line\">image_file = Image.open(<span class=\"string\">\"input.jpg\"</span>)<span class=\"comment\"># 打开图片</span></span><br><span class=\"line\">image_file = image_file.resize((int(image_file.size[<span class=\"number\">0</span>]), int(image_file.size[<span class=\"number\">1</span>]*<span class=\"number\">0.55</span>)))<span class=\"comment\"># 调整图片大小</span></span><br><span class=\"line\"> </span><br><span class=\"line\">output = open(<span class=\"string\">'output.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\">output.write(toText(image_file))</span><br><span class=\"line\">output.close()</span><br></pre></td></tr></table></figure></p>\n<p>需要注意的是要安装依赖PIL。<br>原图：<br><img src=\"/uploads/img/20160720/input.jpg\" alt=\"\"></p>\n<p>字符图：<br><img src=\"/uploads/img/20160720/cover.png\" alt=\"\"></p>\n","excerpt":"","more":"<p>忽然想玩这个图片转化的把戏，是因为之前在知乎上看到一个专栏里用到了下面这个图：<br><img src=\"/uploads/img/20160720/mo.jpg\" alt=\"拿衣服\"><br>当然，那篇专栏没过几小时就被和谐了。我在网上貌似搜到了这个图片转emoji mosaic的网址，供大家戏耍：<a href=\"http://ericandrewlewis.github.io/emoji-mosaic/\">Emoji Mosaic</a>。</p>\n<p>做这个转emoji马赛克应该蛮复杂的，当然它的源码也很容易找到：<a href=\"https://github.com/ericandrewlewis/emoji-mosaic\">ericandrewlewis/emoji-mosaic</a>。但我纯属娱乐又不想花功夫，于是就在晚上学了学把图片转为字符图的代码玩玩。</p>\n<p>代码很简单：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#-*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"> </span><br><span class=\"line\">grey2char = [<span class=\"string\">'@'</span>,<span class=\"string\">'#'</span>,<span class=\"string\">'$'</span>,<span class=\"string\">'%'</span>,<span class=\"string\">'&amp;'</span>,<span class=\"string\">'?'</span>,<span class=\"string\">'*'</span>,<span class=\"string\">'o'</span>,<span class=\"string\">'/'</span>,<span class=\"string\">'&#123;'</span>,<span class=\"string\">'['</span>,<span class=\"string\">'('</span>,<span class=\"string\">'|'</span>,<span class=\"string\">'!'</span>,<span class=\"string\">'^'</span>,<span class=\"string\">'~'</span>,<span class=\"string\">'-'</span>,<span class=\"string\">'_'</span>,<span class=\"string\">':'</span>,<span class=\"string\">';'</span>,<span class=\"string\">','</span>,<span class=\"string\">'.'</span>,<span class=\"string\">'`'</span>,<span class=\"string\">' '</span>]</span><br><span class=\"line\">count = len(grey2char)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">toText</span><span class=\"params\">(image_file)</span>:</span></span><br><span class=\"line\">   image_file = image_file.convert(<span class=\"string\">'L'</span>)<span class=\"comment\"># 转灰度</span></span><br><span class=\"line\">   result = <span class=\"string\">''</span><span class=\"comment\"># 储存字符串</span></span><br><span class=\"line\">   <span class=\"keyword\">for</span> h <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>,  image_file.size[<span class=\"number\">1</span>]):<span class=\"comment\"># height</span></span><br><span class=\"line\">      <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, image_file.size[<span class=\"number\">0</span>]):<span class=\"comment\"># width</span></span><br><span class=\"line\">         gray = image_file.getpixel((w,h))</span><br><span class=\"line\">         result += grey2char[int(gray/(<span class=\"number\">255</span>/(count<span class=\"number\">-1</span>)))]</span><br><span class=\"line\">      result += <span class=\"string\">'\\r\\n'</span></span><br><span class=\"line\">   <span class=\"keyword\">return</span> result</span><br><span class=\"line\"> </span><br><span class=\"line\">image_file = Image.open(<span class=\"string\">\"input.jpg\"</span>)<span class=\"comment\"># 打开图片</span></span><br><span class=\"line\">image_file = image_file.resize((int(image_file.size[<span class=\"number\">0</span>]), int(image_file.size[<span class=\"number\">1</span>]*<span class=\"number\">0.55</span>)))<span class=\"comment\"># 调整图片大小</span></span><br><span class=\"line\"> </span><br><span class=\"line\">output = open(<span class=\"string\">'output.txt'</span>,<span class=\"string\">'w'</span>)</span><br><span class=\"line\">output.write(toText(image_file))</span><br><span class=\"line\">output.close()</span><br></pre></td></tr></table></figure></p>\n<p>需要注意的是要安装依赖PIL。<br>原图：<br><img src=\"/uploads/img/20160720/input.jpg\" alt=\"\"></p>\n<p>字符图：<br><img src=\"/uploads/img/20160720/cover.png\" alt=\"\"></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ciquyzdfx0000ewc5430daxh2","category_id":"ciquyzdgl0003ewc5muf5ldon","_id":"ciquyzdgx0009ewc5a2oaky8i"},{"post_id":"ciquyzdga0001ewc50hml7mkw","category_id":"ciquyzdgv0008ewc5m4f1u4ol","_id":"ciquyzdh0000cewc50vitncdl"},{"post_id":"ciquyzdgn0004ewc5yo7h7how","category_id":"ciquyzdgy000bewc5rouwev2v","_id":"ciquyzdh1000fewc5x50g8m5k"},{"post_id":"ciquyzdgq0005ewc50rqy1m9e","category_id":"ciquyzdh0000eewc53ago5nup","_id":"ciquyzdh7000kewc54xkghyy3"},{"post_id":"ciquyzdgt0007ewc5raetbzlx","category_id":"ciquyzdh3000hewc54ielb52p","_id":"ciquyzdh8000oewc5zhgo3l35"}],"PostTag":[{"post_id":"ciquyzdfx0000ewc5430daxh2","tag_id":"ciquyzdge0002ewc5pp479as9","_id":"ciquyzdh5000iewc5nt6mzisg"},{"post_id":"ciquyzdfx0000ewc5430daxh2","tag_id":"ciquyzdgs0006ewc5hwsxfyvo","_id":"ciquyzdh6000jewc5k0i8uh6i"},{"post_id":"ciquyzdfx0000ewc5430daxh2","tag_id":"ciquyzdgy000aewc5zzy2c1uc","_id":"ciquyzdh7000mewc5680cb82k"},{"post_id":"ciquyzdfx0000ewc5430daxh2","tag_id":"ciquyzdh0000dewc5c1x4rtq8","_id":"ciquyzdh8000newc5hprgkq49"},{"post_id":"ciquyzdga0001ewc50hml7mkw","tag_id":"ciquyzdh2000gewc5wagy7h70","_id":"ciquyzdh8000qewc58519r8og"},{"post_id":"ciquyzdga0001ewc50hml7mkw","tag_id":"ciquyzdh7000lewc56j4y9kz7","_id":"ciquyzdh9000rewc529n9vxf3"},{"post_id":"ciquyzdgn0004ewc5yo7h7how","tag_id":"ciquyzdh8000pewc5yb7rbjwv","_id":"ciquyzdhh000vewc5ru034i01"},{"post_id":"ciquyzdgn0004ewc5yo7h7how","tag_id":"ciquyzdha000sewc5kz4mjp5u","_id":"ciquyzdhi000wewc5yno3nfn5"},{"post_id":"ciquyzdgn0004ewc5yo7h7how","tag_id":"ciquyzdhb000tewc5th948yki","_id":"ciquyzdhj000yewc5zk7ndk29"},{"post_id":"ciquyzdgq0005ewc50rqy1m9e","tag_id":"ciquyzdhg000uewc5n3slzv69","_id":"ciquyzdhm0011ewc5xe1s5gh7"},{"post_id":"ciquyzdgq0005ewc50rqy1m9e","tag_id":"ciquyzdhi000xewc5zjavpf37","_id":"ciquyzdhn0012ewc5j5vogn0x"},{"post_id":"ciquyzdgq0005ewc50rqy1m9e","tag_id":"ciquyzdh0000dewc5c1x4rtq8","_id":"ciquyzdhn0014ewc5iatd86zy"},{"post_id":"ciquyzdgt0007ewc5raetbzlx","tag_id":"ciquyzdhm0010ewc5lqbdts0j","_id":"ciquyzdho0015ewc51lyrfe2k"},{"post_id":"ciquyzdgt0007ewc5raetbzlx","tag_id":"ciquyzdh0000dewc5c1x4rtq8","_id":"ciquyzdho0016ewc57m1woae6"}],"Tag":[{"name":"CentOS","_id":"ciquyzdge0002ewc5pp479as9"},{"name":"Scrapy","_id":"ciquyzdgs0006ewc5hwsxfyvo"},{"name":"ghost.py","_id":"ciquyzdgy000aewc5zzy2c1uc"},{"name":"python","_id":"ciquyzdh0000dewc5c1x4rtq8"},{"name":"English","_id":"ciquyzdh2000gewc5wagy7h70"},{"name":"Hexo","_id":"ciquyzdh7000lewc56j4y9kz7"},{"name":"HMM","_id":"ciquyzdh8000pewc5yb7rbjwv"},{"name":"MEMM","_id":"ciquyzdha000sewc5kz4mjp5u"},{"name":"CRF","_id":"ciquyzdhb000tewc5th948yki"},{"name":"zhihu","_id":"ciquyzdhg000uewc5n3slzv69"},{"name":"Neo4j","_id":"ciquyzdhi000xewc5zjavpf37"},{"name":"PIL","_id":"ciquyzdhm0010ewc5lqbdts0j"}]}}