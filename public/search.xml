<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[基于Neo4j的知乎关系爬虫]]></title>
      <url>http://tripleday.github.io/2016/06/29/zhihu-link/</url>
      <content type="html"><![CDATA[<p>前两天做了一个爬取知乎用户<strong>follow</strong>关系的爬虫。做这个爬虫是受一个知乎专栏的启发<a href="https://zhuanlan.zhihu.com/p/20546546" target="_blank" rel="external">Web Crawler with Python - 09.怎样通过爬虫找出我和轮子哥、四万姐之间的最短关系</a>，我有部分代码参考了xlzd。由于当时也想了解一下NoSQL里Graph Database，于是花了几天时间做了一个简单的爬虫，感觉收获不少。封面图片可以理解成是一个六度分隔理论的直观展现，也是我在做爬虫时的意外验证。</p>
<h1 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h1><p>首先交代一下爬虫所用到的数据库和环境：</p>
<h2 id="MongoDB"><a href="#MongoDB" class="headerlink" title="MongoDB"></a>MongoDB</h2><p>MongoDB一种基于分布式文件存储的数据库，属于NoSQL里的文档型数据库。它的性能较高，面向集合存储，爬虫所抓取的用户信息都存储在其中。<br>在python里使用MongoDB，只需要在本机下载安装MongoDB服务，在python的环境里安装pymongo依赖，<code>pip install pymongo</code>就可以了。如果嫌MongoDB的命令行操作不方便，可以装一个MongoDB的可视化工具<a href="https://robomongo.org/" target="_blank" rel="external">Robomongo</a>。</p>
<h2 id="Neo4j"><a href="#Neo4j" class="headerlink" title="Neo4j"></a>Neo4j</h2><p>Neo4j是一个高性能的,NoSQL图形数据库，它将结构化数据存储在网络上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。<br>关于Neo4j的安装，可以参考这篇博客<a href="http://blog.csdn.net/dyllove98/article/details/8635965" target="_blank" rel="external">Neo4j介绍与使用</a>。Win7环境下，官网<a href="https://neo4j.com/download/" target="_blank" rel="external">下载</a>可以一键安装Neo4j。<br>Neo4j使用类似SQL的查询语言<strong>Cypher</strong>，关于Cypher的使用和简单demo，可以参考<a href="http://www.uml.org.cn/sjjm/201203063.asp" target="_blank" rel="external">Cypher查询语言–Neo4j中的SQL</a>。当然，为了减少学习Cypher的时间成本，我在python环境中安装了<strong>py2neo</strong>，<code>pip install py2neo</code>。py2neo的handbook见<a href="http://py2neo.org/v3/" target="_blank" rel="external">The Py2neo v3 Handbook</a>，我对py2neo依赖库的理解是一个Neo4j的客户端，其中对Neo4j的操作进行了封装。调用py2neo的一个函数，它会自动转化为Cypher语言并以HTTP API向Neo4j服务端口提交一个事务。当然它也支持直接提交Cypher语句到Neo4j执行，有些复杂的数据操作比如寻找两点之间最短路径，py2neo没有提供直接的函数调用，需要我们自己编写Cypher。</p>
<h2 id="python依赖"><a href="#python依赖" class="headerlink" title="python依赖"></a>python依赖</h2><ul>
<li>requests<br>request是一个非常好用的网络依赖包，API文档见<a href="http://www.python-requests.org/en/master/" target="_blank" rel="external">Requests: HTTP for Humans</a>。文档网站的名字“HTTP for Humans”，算是程序员的一种幽默吧。</li>
<li>BeautifulSoup<br>BeautifulSoup依赖库是一个非常实用的HTML解析器，不需要程序员再焦头烂额地写RegEx。虽然开发友好了，但解析时有时会出一些不可思议的bug。API文档见<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" target="_blank" rel="external">Beautiful Soup 4.2.0 文档</a>。</li>
</ul>
<h1 id="爬虫概要"><a href="#爬虫概要" class="headerlink" title="爬虫概要"></a>爬虫概要</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>我爬虫的目的非常简单，和开头的那篇专栏一样：知乎大V—轮子哥（<strong>vczh</strong>）需要通过多少人才能认识并关注我？这里的认识是指单方面的知道，即成为我的follower（不需要为followee，虽然这是肯定的），知道这世界原来还有个知乎用户“<strong>三天三夜</strong>”。</p>
<h2 id="开发思路"><a href="#开发思路" class="headerlink" title="开发思路"></a>开发思路</h2><p>爬虫从我自己的知乎出发，读取我的follower列表，对我的每个follower重复搜索操作，直到搜索到的follower list里有vczh。这个遍历是<strong>BFS</strong>的。当然，为了防止在广度优先搜索时，层与层之间节点数量扩张过快，我限制只搜索follower num<strong>不超过100</strong>的不活跃的小用户，当然我提前调查了轮子哥也有follow一些这种小用户。除了为了防止扩张过快导致的存储空间过大，这样做也给验证六度分隔理论提了更为苛刻的条件，毕竟轮子哥通过其他大V能follow到我的概率是远大于通过小用户的。</p>
<h2 id="代码相关"><a href="#代码相关" class="headerlink" title="代码相关"></a>代码相关</h2><p>整个爬虫的代码我push到Github上，附上<a href="https://github.com/tripleday/zhihu_link" target="_blank" rel="external">链接</a>。<br>贴上几个想到的小细节：</p>
<ul>
<li>这个爬虫需要自己的知乎cookie才能爬取。建议使用chrome，安装<strong>EditThisCookie</strong>插件，将知乎的cookie复制粘贴到zhihu_cookie.json文件。</li>
<li>知乎用户的唯一性不是靠用户名，而是html里内嵌隐藏的<strong>data-id</strong>，在ajax获取数据是发送的表单数据里也需要这个值。所以Neo4j中使用此值可以唯一标识用户。</li>
<li>BeautifulSoup的官方文档里的一张解析器对比表格</li>
</ul>
<p><img src="/uploads/img/20160629/bs.png" alt="BeautifulSoup解析器对比"><br>实际使用钟，在解析<code>https://www.zhihu.com/people/hong-ming-da</code>这条链接时，lxml解析一直都会出错，换成html.parser后解析成功。所以html.parser虽然解析速度慢，但容错性更好一点。</p>
<ul>
<li>其他的细节想到后再补充。</li>
</ul>
<h1 id="爬取结果"><a href="#爬取结果" class="headerlink" title="爬取结果"></a>爬取结果</h1><p>爬虫程序在爬了23928个用户才停下来，即找到了轮子哥。这是爬完的部分用户图：<br><img src="/uploads/img/20160629/whole.png" alt="部分用户关系图"></p>
<p>在命令行执行Cypher语句：<code>MATCH (a {_id : &#39;0970f947b898ecc0ec035f9126dd4e08&#39;}), (b {_id : &#39;bd648b6ef0f14880a522e09ce2752465&#39;}), p = allShortestPaths( (a)-[*..200]-&gt;(b) ) RETURN p</code>可以得到轮子哥到我的最短路径：<br><img src="/uploads/img/20160629/shortestpath.png" alt="最短路径图"></p>
<p>可以发现：轮子哥到我，中间正好经过了6个人。这条路的生成条件是较为严格的。不仅是因为我只选择的小用户进行爬取，而且要知道我的follower目前是只有一个的，轮子哥要连接到我只能通过他。虽然实验得到的 <strong>6</strong> 可能和六度分隔理论恰巧吻合，但鉴于路径选择的苛刻条件，六度的6也许并不只是一种猜想。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[CentOS 6.5 下scrapy与ghost.py的安装干货]]></title>
      <url>http://tripleday.github.io/2016/06/16/centos&scrapy&ghost.py/</url>
      <content type="html"><![CDATA[<p>之前一直在做Scrapy中关于网页动态内容的获取，主要目标是想获得javascript渲染后的网页html源码。<br>在转向使用ghost.py来做脚本解析之前的挖坑爬坑过程中，我已经造访过我所知的大大小小各种论坛、博客以及贴吧和知乎。其中有大方向上指导意义的有知乎里的相关问题：</p>
<ul>
<li><a href="https://www.zhihu.com/question/21471960" target="_blank" rel="external">Python 爬虫如何获取 JS 生成的 URL 和网页内容？</a></li>
<li><a href="https://www.zhihu.com/question/36450326" target="_blank" rel="external">Python爬虫在处理由Javascript动态生成的页面时有哪些解决方案？</a></li>
</ul>
<p>一些前人的技术博客如：</p>
<ul>
<li>开源中国上<a href="http://my.oschina.net/u/1024140?ft=blog" target="_blank" rel="external">斑ban</a>的<a href="http://my.oschina.net/u/1024140/blog/188154" target="_blank" rel="external">《使用python，scrapy写（定制）爬虫的经验，资料，杂》</a>。<br>这篇博客里的总结涉及到爬虫的很多方面，看后受益匪浅，作者乃真大神，有很丰富的爬虫经验。</li>
</ul>
<p>上述几个干货里提到的方法，我基本都去了解了一下，也照着其中的几个方向挖过坑，过些时间我把我在这方面爬的所有坑都总结到一篇博客里。<br>ghost.py算是我掉坑里时间最长的，也是差点就成功的一个，到现在也弃了，弃的原因日后再说。其实，用ghost.py是在PyQt4的基础上转过去的，ghost.py是对<strong>PyQt4</strong>或者<strong>PySide</strong>的一个封装，需要安装其中一个才能运行。</p>
<h1 id="PySide"><a href="#PySide" class="headerlink" title="PySide"></a>PySide</h1><p>当然挖坑的第一步就是安装环境了，win7上安装简便得多，但到linux下就没那么舒服了。<br>下面是我在CentOS 6.5和python2.7.11的环境上安装Scrapy、PySide和Ghost.py过程中查到的有用资料的整合。如嫌下面的字太小，可戳此PDF<a href="http://tripleday.github.io/uploads/pdf/CentOS%26scrapy%26ghost.py.pdf">源地址</a>。<br>

	<div class="row">
	  <iframe src="http://nagland.github.io/viewer/web/viewer.html?val=http://tripleday.github.io/uploads/pdf/CentOS%26scrapy%26ghost.py.pdf" style="width:100%; height:900px"></iframe>
	</div>


<br>上面的PDF里ghost.py用的是PySide。PySide和PyQt4的功能和API近乎一致，我的理解是：PyQt4是PySide的商业化版本，两者都是Qt进行维护。</p>
<h1 id="PyQt4"><a href="#PyQt4" class="headerlink" title="PyQt4"></a>PyQt4</h1><p>我曾经在用PySide的时候遇到无法解决的Core Dump的bug，想转去试一下PyQt4看会不会好点，虽然结果是bug更频繁，但我还是列出安装PyQt4的一些小tips吧，希望后来人少走点弯路。<br>安装PyQt4之前是需要安装<strong>SIP</strong>的。SIP是一个自动为C和C++库生成Python扩展模块的工具。为了方便开发PyQt，SIP于1998被“Riverbank Computing”公司创造出来。不过，SIP不专用于PyQt，而是适用于所有的C和C++库。但据说好像现在只有PyQt一直在坚持用SIP，很多别人家的项目在需要对C或C++封装调用的时候都用SWIG了。</p>
<p>在安装过程中最让人抓狂的SIP和PyQt4的版本对应问题：某个固定版本的SIP只能支持少数几个版本的PyQt，有比较麻烦的兼容性问题。曾经在安装时，要么提示SIP版本过高，PyQt无法编译；要么PyQt版本过高，SIP不能支持。<br>贴一个能够成功安装的博客链接：<a href="http://blog.csdn.net/dgatiger/article/details/50331361" target="_blank" rel="external">CentOS7.1下python2.7.10安装PyQt4</a></p>
<p>文中SIP的安装代码：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://downloads.sourceforge.net/project/pyqt/sip/sip-4.17/sip-4.17.tar.gz</span><br><span class="line">tar xvf sip-4.17.tar.gz</span><br><span class="line"><span class="built_in">cd</span> sip-4.17</span><br><span class="line">python configure.py</span><br><span class="line">make &amp; make install &amp; make clean</span><br></pre></td></tr></table></figure></p>
<p>PyQt的安装代码：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://downloads.sourceforge.net/project/pyqt/PyQt4/PyQt-4.11.4/PyQt-x11-gpl-4.11.4.tar.gz</span><br><span class="line">tar xvf PyQt-x11-gpl-4.11.4.tar.gz</span><br><span class="line"><span class="built_in">cd</span> PyQt-x11-gpl-4.11.4</span><br><span class="line">python configure.py -q  /usr/lib64/qt4/bin/qmake</span><br><span class="line">make &amp; make install &amp; make clean</span><br></pre></td></tr></table></figure></p>
<p>这篇博客里用的是<strong>sip-4.17</strong>和<strong>PyQt-4.11.4</strong>是能够成功的一对版本。另外，Python2.7最高只能支持到PyQt4，PyQt5好像需要Python3.X的环境；同时Python2与Python3的兼容性也较差。所以为了避免版本上的麻烦，个人建议Python2还是老老实实用PyQt4，Python3的也使用对应的PyQt5。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>http://tripleday.github.io/2016/06/12/hello-world/</url>
      <content type="html"><![CDATA[<p>This is my <strong>first blog</strong> after I established this site using <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a> and <a href="https://github.com/stiekel/hexo-theme-random" target="_blank" rel="external">random</a>.<br>Here are some tests for Hexo:</p>
<h1 id="Code-Test"><a href="#Code-Test" class="headerlink" title="Code Test:"></a>Code Test:</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo generate</span><br><span class="line">$ hexo server</span><br><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<h1 id="PDF-Test"><a href="#PDF-Test" class="headerlink" title="PDF Test:"></a>PDF Test:</h1>

	<div class="row">
	  <iframe src="http://nagland.github.io/viewer/web/viewer.html?val=http://tripleday.github.io/uploads/pdf/Clean%20Code.pdf" style="width:100%; height:900px"></iframe>
	</div>



<h1 id="iFrame-Test"><a href="#iFrame-Test" class="headerlink" title="iFrame Test:"></a>iFrame Test:</h1><iframe src="http://www.seu.edu.cn/english/main.htm" width="100%" height="500" frameborder="0" allowfullscreen></iframe>
<h1 id="Picture-Test"><a href="#Picture-Test" class="headerlink" title="Picture Test:"></a>Picture Test:</h1><p><img src="/uploads/img/20160612/facebook.jpg" alt="Facebook"></p>
<h1 id="Youtube-Test"><a href="#Youtube-Test" class="headerlink" title="Youtube Test:"></a>Youtube Test:</h1><div class="video-container"><iframe src="//www.youtube.com/embed/https://youtu.be/QBJxGklvHRg" frameborder="0" allowfullscreen></iframe></div>
<h1 id="Youku-Test"><a href="#Youku-Test" class="headerlink" title="Youku Test:"></a>Youku Test:</h1><div class="video-container"><iframe height="480" width="100%" src="http://player.youku.com/embed/XMTU3NjExOTUwMA==" frameborder="0" allowfullscreen></iframe></div>
]]></content>
    </entry>
    
  
  
    
    <entry>
      <title><![CDATA[About]]></title>
      <url>http://tripleday.github.io/about/index.html</url>
      <content type="html"><![CDATA[<h1 id="About-Me"><a href="#About-Me" class="headerlink" title="About Me"></a>About Me</h1><p>My name is Haotian Wu(吴昊天). I’m a master student in <a href="http://cse.seu.edu.cn/en/index.html" target="_blank" rel="external">School of Computer Science &amp; Engineering</a> at <a href="http://www.seu.edu.cn/english/main.htm" target="_blank" rel="external">Southeast University</a> and will graduate in Summer 2018.</p>
<ul>
<li>Research Interests:<ul>
<li>Web Crawler</li>
<li>Data Mining &amp; Visualization</li>
<li>Ad Hoc Networks</li>
</ul>
</li>
<li>Sports: <ul>
<li>Badminton</li>
<li>Swimming</li>
</ul>
</li>
</ul>
<h1 id="Contact"><a href="#Contact" class="headerlink" title="Contact"></a>Contact</h1><p>Just to avoid spams, here is the Base64 code of my e-mail address:<br><code>aGFvdGlhbnd1c2V1QGdtYWlsLmNvbQ==</code></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[categories]]></title>
      <url>http://tripleday.github.io/categories/index.html</url>
      <content type="html"></content>
    </entry>
    
    <entry>
      <title><![CDATA[tags]]></title>
      <url>http://tripleday.github.io/tags/index.html</url>
      <content type="html"></content>
    </entry>
    
  
</search>
